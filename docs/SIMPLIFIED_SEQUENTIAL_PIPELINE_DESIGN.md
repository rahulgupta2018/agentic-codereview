# Simplified Sequential Agent Pipeline Design

**Status**: Design Review (December 8, 2025)  
**Date**: December 8, 2025  
**Architecture Pattern**: Deterministic Sequential Pipeline  
**Priority**: GitHub Integration with ADK Built-in Artifacts  
**Inspiration**: [ADK Sequential Workflows](https://raphaelmansuy.github.io/adk_training/docs/sequential_workflows)

---

## ğŸ¯ Design Philosophy

**Goal**: Create a simple, maintainable, deterministic pipeline for GitHub PR code reviews.

**Key Principles**:
1. âœ… **Sequential execution** - all analysis agents run in order, every time (deterministic)
2. âœ… **No dynamic routing** - remove complexity of planning + dynamic selection  
3. âœ… **ADK built-in artifacts** - use ADK's `tool_context.save_artifact()` for persistence
4. âœ… **Session-based organization** - artifacts organized by session/user/PR  
5. âœ… **Separate analysis pipeline** - encapsulate analysis agents as sub-pipeline for maintainability

### Why Simplify?

**Current Problems**:
- âŒ Planning Agent + Dynamic Router adds unnecessary complexity
- âŒ Agents don't reliably call `save_analysis_result()` tool (LLM inconsistency)
- âŒ Mixing session state and disk artifacts creates confusion
- âŒ Hard to debug when execution path varies

**Solution**:
- âœ… Fixed sequential pipeline - same agents, same order, every time
- âœ… ADK handles artifact persistence - no custom disk I/O
- âœ… Clear separation: Fetch â†’ Analyze â†’ Report â†’ Publish
- âœ… Each step is predictable and testable

---

## ğŸ—ï¸ Architecture Overview

### High-Level Flow

```
GitHub Webhook/API Call
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Orchestrator Agent (Root)          â”‚
â”‚   Entry point for all API requests      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    GitHub PR Review Pipeline            â”‚
â”‚      (SequentialAgent)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Step 1: Fetch
    Step 2: Analyze (nested pipeline)
    Step 3: Report
    Step 4: Publish
         â†“
    âœ… Complete
```

### Detailed Sequential Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: GitHub Fetcher Agent                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Purpose: Fetch PR data from GitHub API                       â”‚
â”‚ Input:   github_context from session state                   â”‚
â”‚          { repo: "owner/repo", pr_number: 42, ... }          â”‚
â”‚ Tools:   â€¢ fetch_github_pr_files() or mock                   â”‚
â”‚ Output:  â€¢ session.state["github_pr_data"] = {               â”‚
â”‚            files: [...], diffs: [...], metadata: {...}       â”‚
â”‚          }                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Analysis Pipeline (SequentialAgent - NESTED)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Purpose: Encapsulate all analysis agents for maintainability â”‚
â”‚ Design:  Separate sub-pipeline within orchestrator           â”‚
â”‚ Execution: Sequential (deterministic order)                  â”‚
â”‚                                                               â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ 2a. Security Agent                                     â”‚  â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚  â”‚
â”‚ â”‚ â€¢ Call: scan_security_vulnerabilities(code)            â”‚  â”‚
â”‚ â”‚ â€¢ Generate: JSON with vulnerabilities, OWASP risks     â”‚  â”‚
â”‚ â”‚ â€¢ Save: tool_context.save_artifact(                    â”‚  â”‚
â”‚ â”‚         filename="security_analysis.json",             â”‚  â”‚
â”‚ â”‚         artifact=json_data                             â”‚  â”‚
â”‚ â”‚       )                                                â”‚  â”‚
â”‚ â”‚ â€¢ Location: ADK manages storage                        â”‚  â”‚
â”‚ â”‚             (artifacts/<session_id>/...)               â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                        â†“                                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ 2b. Code Quality Agent                                 â”‚  â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚  â”‚
â”‚ â”‚ â€¢ Call: analyze_complexity(), analyze_static_code()    â”‚  â”‚
â”‚ â”‚ â€¢ Generate: JSON with metrics, quality issues          â”‚  â”‚
â”‚ â”‚ â€¢ Save: tool_context.save_artifact(                    â”‚  â”‚
â”‚ â”‚         filename="quality_analysis.json", ...          â”‚  â”‚
â”‚ â”‚       )                                                â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                        â†“                                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ 2c. Engineering Practices Agent                        â”‚  â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”‚  â”‚
â”‚ â”‚ â€¢ Call: evaluate_engineering_practices()               â”‚  â”‚
â”‚ â”‚ â€¢ Generate: JSON with best practice violations         â”‚  â”‚
â”‚ â”‚ â€¢ Save: tool_context.save_artifact(                    â”‚  â”‚
â”‚ â”‚         filename="engineering_analysis.json", ...      â”‚  â”‚
â”‚ â”‚       )                                                â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                        â†“                                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ 2d. Carbon Emission Agent                              â”‚  â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚  â”‚
â”‚ â”‚ â€¢ Call: analyze_carbon_footprint()                     â”‚  â”‚
â”‚ â”‚ â€¢ Generate: JSON with environmental impact             â”‚  â”‚
â”‚ â”‚ â€¢ Save: tool_context.save_artifact(                    â”‚  â”‚
â”‚ â”‚         filename="carbon_analysis.json", ...           â”‚  â”‚
â”‚ â”‚       )                                                â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Report Synthesizer Agent                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Purpose: Generate comprehensive markdown report              â”‚
â”‚ Input:   Load all analysis artifacts via ADK                 â”‚
â”‚ Tools:   â€¢ load_artifacts(session_id) â†’ returns all JSONs    â”‚
â”‚          â€¢ ADK artifact system handles retrieval             â”‚
â”‚ Process: â€¢ Parse each analysis JSON                          â”‚
â”‚          â€¢ Synthesize findings into sections:                â”‚
â”‚            - Executive Summary                               â”‚
â”‚            - Security Vulnerabilities (table)                â”‚
â”‚            - Code Quality Metrics                            â”‚
â”‚            - Engineering Best Practices                      â”‚
â”‚            - Environmental Impact                            â”‚
â”‚            - Consolidated Recommendations                    â”‚
â”‚ Output:  â€¢ Comprehensive markdown document                   â”‚
â”‚          â€¢ Save: tool_context.save_artifact(                 â”‚
â”‚            filename="final_report.md", ...                   â”‚
â”‚          )                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: GitHub Publisher Agent                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Purpose: Post review to GitHub PR                            â”‚
â”‚ Input:   Load final_report.md from ADK artifacts             â”‚
â”‚ Tools:   â€¢ post_github_pr_comment(report_md)                 â”‚
â”‚          â€¢ add_inline_annotations(findings)                  â”‚
â”‚ Actions: â€¢ Post main review comment with full report         â”‚
â”‚          â€¢ Add inline comments on specific code lines        â”‚
â”‚          â€¢ Update PR review status (approved/changes needed) â”‚
â”‚ Output:  GitHub PR updated with review                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Implementation Structure

### File Organization

```
agent_workspace/orchestrator_agent/
â”œâ”€â”€ agent.py                               # Main orchestrator (root agent)
â”‚   â”œâ”€â”€ _create_github_pipeline()          # Creates main pipeline
â”‚   â””â”€â”€ _create_analysis_pipeline()        # Creates nested analysis sub-pipeline
â”‚
â””â”€â”€ sub_agents/
    â”œâ”€â”€ github_fetcher_agent/              # Step 1
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ agent.py
    â”‚
    â”œâ”€â”€ analysis_agents/                   # Step 2 (grouped)
    â”‚   â”œâ”€â”€ security_agent/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â””â”€â”€ agent.py
    â”‚   â”œâ”€â”€ code_quality_agent/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â””â”€â”€ agent.py
    â”‚   â”œâ”€â”€ engineering_practices_agent/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â””â”€â”€ agent.py
    â”‚   â””â”€â”€ carbon_emission_agent/
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â””â”€â”€ agent.py
    â”‚
    â”œâ”€â”€ report_synthesizer_agent/          # Step 3
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ agent.py
    â”‚
    â””â”€â”€ github_publisher_agent/            # Step 4
        â”œâ”€â”€ __init__.py
        â””â”€â”€ agent.py
```

### Code Structure (Orchestrator)

```python
# agent_workspace/orchestrator_agent/agent.py

from google.adk.agents import Agent, SequentialAgent

class CodeReviewOrchestratorAgent:
    """
    Orchestrator for GitHub PR code reviews.
    Creates a simple, deterministic sequential pipeline.
    """
    
    def __init__(self):
        # Load individual agents
        self.github_fetcher = self._load_github_fetcher()
        self.analysis_pipeline = self._create_analysis_pipeline()
        self.report_synthesizer = self._load_report_synthesizer()
        self.github_publisher = self._load_github_publisher()
        
        # Create main pipeline
        self.root_agent = self._create_github_pipeline()
    
    def _create_analysis_pipeline(self) -> SequentialAgent:
        """
        Create nested analysis pipeline.
        Encapsulates all 4 analysis agents for maintainability.
        """
        return SequentialAgent(
            name="AnalysisPipeline",
            sub_agents=[
                self._load_security_agent(),
                self._load_code_quality_agent(),
                self._load_engineering_agent(),
                self._load_carbon_agent(),
            ],
            description="Run all code analysis agents sequentially"
        )
    
    def _create_github_pipeline(self) -> SequentialAgent:
        """
        Create main GitHub PR review pipeline.
        Simple, deterministic, easy to understand.
        """
        return SequentialAgent(
            name="GitHubPRReviewPipeline",
            sub_agents=[
                self.github_fetcher,        # Step 1: Fetch
                self.analysis_pipeline,     # Step 2: Analyze (nested)
                self.report_synthesizer,    # Step 3: Report
                self.github_publisher,      # Step 4: Publish
            ],
            description="Complete GitHub PR review workflow"
        )
```

---

## ğŸ“¦ ADK Artifact System Usage

### How ADK Artifacts Work

ADK provides built-in artifact management through `tool_context.save_artifact()`:

```python
# In analysis agent tool
async def scan_security_vulnerabilities(
    code: str,
    tool_context: ToolContext
) -> Dict[str, Any]:
    """Scan code for security vulnerabilities."""
    
    # Perform analysis
    results = {
        "agent": "security_agent",
        "vulnerabilities": [...],
        "owasp_risks": [...]
    }
    
    # Save artifact via ADK
    from google.genai import types
    artifact_part = types.Part.from_text(
        text=json.dumps(results, indent=2)
    )
    
    version = await tool_context.save_artifact(
        filename="security_analysis.json",
        artifact=artifact_part
    )
    
    return {
        "status": "success",
        "artifact_version": version,
        "findings_count": len(results["vulnerabilities"])
    }
```

### Artifact Organization

ADK organizes artifacts by:
- **Session ID**: Each API request gets unique session
- **User ID**: Identified from API request
- **App Name**: `orchestrator_agent`

**Expected Structure** (managed by ADK):
```
ADK_STORAGE/
â””â”€â”€ artifacts/
    â””â”€â”€ orchestrator_agent/
        â””â”€â”€ <user_id>/
            â””â”€â”€ <session_id>/
                â”œâ”€â”€ security_analysis.json
                â”œâ”€â”€ quality_analysis.json
                â”œâ”€â”€ engineering_analysis.json
                â”œâ”€â”€ carbon_analysis.json
                â””â”€â”€ final_report.md
```

### Loading Artifacts (Report Synthesizer)

```python
# In report synthesizer agent
async def synthesize_report(
    tool_context: ToolContext
) -> str:
    """Load all analysis artifacts and create comprehensive report."""
    
    # ADK provides access to artifacts for current session
    # Implementation depends on ADK 1.17.0 artifact API
    
    session = tool_context.session
    session_id = session.id
    
    # Load artifacts (ADK API)
    security_data = await tool_context.load_artifact("security_analysis.json")
    quality_data = await tool_context.load_artifact("quality_analysis.json")
    engineering_data = await tool_context.load_artifact("engineering_analysis.json")
    carbon_data = await tool_context.load_artifact("carbon_analysis.json")
    
    # Synthesize markdown report
    report_md = generate_comprehensive_report(
        security=json.loads(security_data),
        quality=json.loads(quality_data),
        engineering=json.loads(engineering_data),
        carbon=json.loads(carbon_data)
    )
    
    # Save final report
    report_part = types.Part.from_text(text=report_md)
    await tool_context.save_artifact(
        filename="final_report.md",
        artifact=report_part
    )
    
    return report_md
```

---

## ğŸ­ Comparison: Old vs New Design

| Aspect | Old Design (Complex) | New Design (Simplified) |
|--------|---------------------|------------------------|
| **Pipeline Structure** | Fetcher â†’ Planning â†’ Router â†’ Report â†’ Publish | Fetcher â†’ Analysis Pipeline â†’ Report â†’ Publish |
| **Agent Count** | 9 agents | 6 agents |
| **Dynamic Behavior** | Planning decides which agents run | All agents run every time (deterministic) |
| **Complexity** | Planning Agent + Dynamic Router + Registry | Simple SequentialAgent nesting |
| **Session State Keys** | 6+ keys (classification, plan, analyses) | 2 keys (github_pr_data, analyses) |
| **Artifact Persistence** | Custom tools + disk I/O | ADK built-in artifact system |
| **Maintainability** | Complex routing logic, hard to debug | Clear sequential flow, easy to understand |
| **Testability** | Hard (varies by planning decision) | Easy (same path every time) |
| **Execution Time** | ~4-5 minutes | ~4-5 minutes (same) |
| **Reliability** | LLM makes routing decisions | No LLM decisions, just execute |

### What We Removed

1. **Classifier Agent** - Not needed for GitHub webhooks (we know it's a PR review)
2. **Planning Agent** - Not needed when all agents run every time
3. **Dynamic Router** - Not needed without dynamic selection
4. **Proxy Tools** - `select_security_agent()`, etc. (not needed)
5. **Agent Registry** - Not needed without dynamic lookup
6. **execution_plan state** - Not needed without planning
7. **Custom save tools** - Use ADK's built-in `save_artifact()`

### What We Kept

1. **GitHub Fetcher** - Essential for getting PR data
2. **All 4 Analysis Agents** - Core value (security, quality, engineering, carbon)
3. **Report Synthesizer** - Essential for creating final output
4. **GitHub Publisher** - Essential for posting to GitHub
5. **Sequential Execution** - Proven reliable pattern

---

## âœ… Benefits of Simplified Design

### 1. **Predictability**
- Same agents run every time
- No LLM-based decisions that could vary
- Easy to test and validate

### 2. **Simplicity**
- Fewer agents = less code = less to maintain
- Clear linear flow: Fetch â†’ Analyze â†’ Report â†’ Publish
- New team members can understand quickly

### 3. **Reliability**
- No reliance on LLM to "remember" to call save tools
- ADK handles artifact persistence
- Deterministic execution path

### 4. **Maintainability**
- Analysis pipeline is separate sub-pipeline
- Can update analysis agents independently
- Clear separation of concerns

### 5. **Debuggability**
- Same execution path every time
- Easy to add logging at each step
- Can test each agent in isolation

---

## ğŸš€ Implementation Plan

### Phase 1: Update Orchestrator (2-3 hours)

1. **Remove complexity**:
   ```python
   # DELETE these agents/components:
   - classifier_agent/
   - planning_agent/
   - dynamic_router_agent/
   - Agent registry dict
   - Proxy selection tools
   ```

2. **Create analysis pipeline**:
   ```python
   def _create_analysis_pipeline(self) -> SequentialAgent:
       return SequentialAgent(
           name="AnalysisPipeline",
           sub_agents=[
               security_agent,
               code_quality_agent,
               engineering_agent,
               carbon_agent,
           ]
       )
   ```

3. **Simplify main pipeline**:
   ```python
   def _create_github_pipeline(self) -> SequentialAgent:
       return SequentialAgent(
           name="GitHubPRReviewPipeline",
           sub_agents=[
               github_fetcher,
               analysis_pipeline,      # Nested!
               report_synthesizer,
               github_publisher,
           ]
       )
   ```

### Phase 2: Update Analysis Agents (1-2 hours)

For each analysis agent:

1. **Simplify instructions** - remove mentions of planning/routing
2. **Keep artifact saving** - use ADK's `tool_context.save_artifact()`
3. **Remove output_key if not needed** - ADK saves artifacts anyway
4. **Focus on analysis quality** - simpler agents = better prompts

### Phase 3: Update Report Synthesizer (2-3 hours)

1. **Use ADK artifact loading**:
   ```python
   async def load_all_analyses(tool_context: ToolContext):
       # Query ADK artifact system for current session
       artifacts = await tool_context.list_artifacts()
       # Load each analysis JSON
       # Return dict of all analyses
   ```

2. **Synthesize comprehensive report**:
   - Parse all 4 JSON analyses
   - Create markdown with all sections
   - Save as `final_report.md` artifact

### Phase 4: Testing (2-3 hours)

1. **Unit tests** for each agent
2. **Integration test** for full pipeline
3. **E2E test** with mock GitHub data
4. **Validate artifacts** are saved correctly

### Phase 5: Documentation (1-2 hours)

1. Update README with new architecture
2. Update API documentation
3. Create architecture diagram
4. Update CHANGELOG

**Total Estimated Time**: 8-13 hours

---

## ğŸ“ Session State Design

### Minimal State Keys

```python
session.state = {
    # Input (from API request)
    "github_context": {
        "repo": "owner/repo",
        "pr_number": 42,
        "head_sha": "abc123",
        ...
    },
    
    # Step 1 output
    "github_pr_data": {
        "files": [...],
        "diffs": [...],
        "metadata": {...}
    },
    
    # Steps 2a-2d outputs (optional - artifacts are primary storage)
    "security_analysis": {...},      # Also saved as artifact
    "quality_analysis": {...},       # Also saved as artifact
    "engineering_analysis": {...},   # Also saved as artifact
    "carbon_analysis": {...},        # Also saved as artifact
    
    # Step 3 output (optional - artifact is primary storage)
    "final_report": "..."            # Also saved as artifact
}
```

**Note**: Session state is ephemeral. Artifacts are the **source of truth** for persistent data.

---

## ğŸ” Open Questions

1. **ADK Artifact API**: 
   - Does ADK 1.17.0 provide `tool_context.load_artifact(filename)`?
   - Or do we need `tool_context.list_artifacts()` + query?
   - Check ADK documentation for artifact retrieval APIs

2. **GitHub Publisher**:
   - Should it load report from artifacts or session state?
   - Artifacts are more reliable (persisted)

3. **Error Handling**:
   - If analysis agent fails, should pipeline continue?
   - Or stop and return partial results?

4. **Artifact Cleanup**:
   - Should old artifacts be deleted after PR closes?
   - Retention policy (30 days, 90 days)?

---

## ğŸ“š References

- [ADK Sequential Workflows](https://raphaelmansuy.github.io/adk_training/docs/sequential_workflows)
- [ADK Artifact Documentation](https://developers.google.com/adk/artifacts) (TODO: verify link)
- [GitHub PR Review API](https://docs.github.com/en/rest/pulls/reviews)

---

## âœï¸ Next Steps

**Immediate**:
1. âœ… Review and approve this simplified design
2. â³ Verify ADK 1.17.0 artifact API capabilities
3. â³ Create implementation task breakdown
4. â³ Update agent_workspace/ structure

**Future Considerations**:
- Web UI pipeline (if needed later)
- Agent parallelization (if speed becomes critical)
- Selective agent execution (if resources constrained)

But for now: **Keep it simple, make it work, iterate based on real usage.**

---

*End of Design Document*
