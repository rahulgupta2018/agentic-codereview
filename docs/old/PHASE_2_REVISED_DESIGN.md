# Phase 2: Deterministic Workflow Orchestration with Decision Frameworks

**Status:** Design Review  
**Version:** 3.0  
**Date:** November 28, 2025  
**Prerequisites:** Phase 1 MVP completed

---

## ğŸ“‹ Executive Summary

**Framework:** Google ADK (Agent Development Kit) - Python SDK  
**GitHub Integration:** PyGithub library OR direct HTTP calls (no Microsoft Agent Framework)

Based on Google ADK best practices, Phase 2 **abandons custom orchestration logic** in favor of **deterministic ADK workflow patterns** using:

- **SequentialAgent** for ordered pipeline execution
- **Decision Frameworks** for request source routing (API vs Web UI)
- **PlanReActPlanner** for dynamic intent analysis and agent selection
- **ParallelAgent** for efficient multi-agent execution (where appropriate)
- **No custom orchestration code** - pure ADK patterns

### GitHub Integration Options (All work with Google ADK):

1. **PyGithub Library** âœ… Recommended
   - `pip install PyGithub`
   - Wrap as `FunctionTool` for agents
   - Handles auth, pagination, rate limiting

2. **Direct HTTP with httpx/requests** âœ… Simple
   - No extra dependencies
   - Full control over API calls
   - Good for MVP

3. **GitHub MCP Server** âœ… Advanced
   - Model Context Protocol integration
   - Auto-discovers GitHub tools
   - Good for complex workflows

### Key Design Principles

1. âœ… **Deterministic Workflows** - Predictable, ordered execution
2. âœ… **ADK Native Patterns** - Use SequentialAgent, ParallelAgent, Decision Frameworks
3. âœ… **No Custom Orchestration** - Eliminate custom if/elif logic
4. âœ… **Plan-ReAct for Intelligence** - LLM-driven agent selection
5. âœ… **GitHub Integration Ready** - Designed for webhook â†’ queue â†’ worker pattern

### Critical Understanding: Workflow Agents vs Sub-Agents

> **Workflow Agents (Containers):** SequentialAgent, ParallelAgent, LoopAgent  
> - These are **CONTAINERS** that run sub-agents in a specific pattern  
> - They don't do any work themselves  
> - They just control WHEN and HOW sub-agents run  
>
> **Sub-Agents (Workers):** SourceDetector, GitHubAgent, PlanningAgent, SecurityAgent, etc.  
> - These are **REGULAR AGENTS** (created with `Agent()`)  
> - They do the actual work (call LLMs, use tools, process data)  
> - They are placed inside workflow containers  

**Example:**
```python
# âœ… CORRECT: SequentialAgent contains sub-agents
pipeline = SequentialAgent(
    name="GitHubPipeline",
    sub_agents=[
        github_agent,         # â† Agent (sub-agent)
        planning_agent,       # â† Agent (sub-agent)
        report_synthesizer    # â† Agent (sub-agent)
    ]
)
```

**Hierarchy in Our System:**
```
RootOrchestrator (SequentialAgent) â† WORKFLOW CONTAINER
  â”‚
  â”œâ”€ sub_agents: [SourceDetector] â† AGENT (worker)
  â”‚
  â””â”€ dynamic_agents: {
       'github_pipeline': GitHubPipeline (SequentialAgent) â† WORKFLOW CONTAINER
                           â”‚
                           â”œâ”€ GitHubAgent â† AGENT (worker)
                           â”œâ”€ PlanningAgent â† AGENT (worker)
                           â”œâ”€ ExecutionPipeline (ParallelAgent) â† WORKFLOW CONTAINER
                           â”‚   â”‚
                           â”‚   â”œâ”€ SecurityAgent â† AGENT (worker)
                           â”‚   â”œâ”€ CodeQualityAgent â† AGENT (worker)
                           â”‚   â”œâ”€ EngineeringAgent â† AGENT (worker)
                           â”‚   â””â”€ CarbonAgent â† AGENT (worker)
                           â”‚
                           â”œâ”€ ReportSynthesizer â† AGENT (worker)
                           â””â”€ GitHubPublisher â† AGENT (worker)
     }
```

**Remember:** SourceDetector, GitHubAgent, ClassifierAgent, PlanningAgent, ReportSynthesizer, GitHubPublisher are **ALL SUB-AGENTS** (not orchestrators)!

### Quick Start: GitHub Integration with Google ADK

```bash
# Install dependencies
pip install google-adk PyGithub httpx

# Set environment variables
export GITHUB_TOKEN="ghp_your_token_here"
export GOOGLE_API_KEY="your_gemini_key_here"
```

```python
# Minimal example: GitHub PR review agent with Google ADK
from google.adk.agents import Agent
from google.adk.tools import FunctionTool
from github import Github

# Setup GitHub client
gh = Github(os.getenv("GITHUB_TOKEN"))

def fetch_pr_files(repo: str, pr_number: int) -> dict:
    """Fetch PR files using PyGithub."""
    repo_obj = gh.get_repo(repo)
    pr = repo_obj.get_pull(pr_number)
    return {
        "files": [{"filename": f.filename, "patch": f.patch} 
                  for f in pr.get_files()]
    }

# Create agent with GitHub tool
agent = Agent(
    name="GitHubReviewer",
    model="gemini-2.5-flash",
    tools=[FunctionTool(
        name="fetch_pr_files",
        description="Fetch PR files from GitHub",
        function=fetch_pr_files
    )],
    instruction="Use fetch_pr_files to get PR data and review the code"
)
```

---

## ğŸ“š ADK Best Practices Review

### Workflow Patterns (Source: ADK Training)

```
Sequential (Assembly Line): One after another
  Step 1 â†’ Step 2 â†’ Step 3 â†’ Step 4
  Use: Pipelines, dependencies, order matters

Parallel (Fan-out/Gather): Multiple tasks at once
  â”Œâ”€â”€â”€ Task A â”€â”€â”€â”
  â”œâ”€â”€â”€ Task B â”€â”€â”€â”¤ â†’ Merge Results
  â””â”€â”€â”€ Task C â”€â”€â”€â”˜
  Use: Independent tasks, speed critical

Loop (Iterative Refinement): Repeat until good enough
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  â”Œâ”€â”€â–º Critic â”€â”€â”€â”â”‚
  â”‚  â””â”€â”€â”€ Refiner â—„â”€â”˜â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Use: Quality improvement, retry logic
```

### Decision Framework Pattern

**Generic ADK Example** (illustrative pattern):

```python
# Step 1: Define routing logic
def route_by_source(context, result):
    """Routing function reads agent output and returns pipeline key."""
    source = result.get('source', '')
    if source == 'github_webhook':
        return 'github_pipeline'
    elif source == 'web_ui':
        return 'web_pipeline'
    else:
        return 'default_handler'

# Step 2: Create detector agent (determines which route to take)
source_detector_agent = Agent(
    name="source_detector_agent",
    model="gemini-2.5-flash",
    instruction="Analyze request and determine source type",
    output_key="source_detection"  # Output used by routing_function
)

# Step 3: Create workflow with dynamic routing
workflow = SequentialAgent(
    sub_agents=[detector_agent],  # Runs first
    dynamic_agents={
        'github_pipeline': github_pipeline_workflow,
        'web_pipeline': web_pipeline_workflow,
        'default_handler': default_workflow
    },
    routing_function=route_by_source  # Reads detector_agent output
)
```

**Our Implementation** (see complete code below):

```python
# Our actual implementation uses SourceDetector agent
source_detector = Agent(name="SourceDetector", ...)  # Sub-agent

root_orchestrator = SequentialAgent(
    sub_agents=[source_detector],  # Runs first
    dynamic_agents={
        'github_pipeline': GitHubPipeline,  # SequentialAgent
        'web_pipeline': WebPipeline         # SequentialAgent
    },
    routing_function=route_by_source  # Reads source_detector output
)
```

**Key Point:** The agent in `sub_agents` (e.g., `source_detector` or `SourceDetector`) is NOT an orchestrator - it's a regular `Agent()` that outputs data used by `routing_function` to select the appropriate pipeline from `dynamic_agents`.

### Plan-ReAct Pattern for Agent Selection

```python
# Planner determines which agents to employ
planning_agent = Agent(
    name="planner",
    model="gemini-2.5-flash",
    planner=PlanReActPlanner(),
    tools=[security_tool, quality_tool, practices_tool],
    instruction="""Analyze code review request and determine:
    - Which analysis types are needed
    - What order to execute them
    - Whether parallel or sequential execution"""
)
```

---

## ğŸ—ï¸ Revised Architecture

### High-Level Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  GitHub Webhook (Entry Point)               â”‚
â”‚         POST /api/webhook/github (PR opened/updated)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ <100ms
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Cloud Run #1 - API Service                â”‚
â”‚   â€¢ Validates HMAC signature                                â”‚
â”‚   â€¢ Enriches with repo metadata                             â”‚
â”‚   â€¢ Publishes to Cloud Pub/Sub                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Asynchronous (no waiting)
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Cloud Pub/Sub Queue                    â”‚
â”‚   â€¢ Decouples webhook from processing                       â”‚
â”‚   â€¢ Handles multiple concurrent PRs                         â”‚
â”‚   â€¢ Rate limiting and retry logic                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Push to worker (when available)
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Cloud Run #2 - Worker Service (ADK)             â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    RootOrchestrator (SequentialAgent) â† WORKFLOW      â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚    sub_agents: [SourceDetector] â† ALWAYS RUNS FIRST  â”‚  â”‚
â”‚  â”‚    â”‚                                                  â”‚  â”‚
â”‚  â”‚    â”œâ”€ SourceDetector (Agent) â† SUB-AGENT             â”‚  â”‚
â”‚  â”‚    â”‚   Determines: github_webhook or web_ui          â”‚  â”‚
â”‚  â”‚    â”‚                                                  â”‚  â”‚
â”‚  â”‚    â””â”€ routing_function: route_by_source()            â”‚  â”‚
â”‚  â”‚        â”‚                                              â”‚  â”‚
â”‚  â”‚        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚
â”‚  â”‚        â–¼                 â–¼                 â–¼         â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚ GitHubPipeline (SequentialAgent) â† WORKFLOW  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                                               â”‚   â”‚  â”‚
â”‚  â”‚  â”‚ sub_agents:                                   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚   1. GitHubAgent (Agent) â† SUB-AGENT          â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      Fetches PR files via GitHub API          â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                                               â”‚   â”‚  â”‚
â”‚  â”‚  â”‚   2. PlanningAgent (Agent) â† SUB-AGENT        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      Uses PlanReActPlanner                    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      Selects which analysis agents to run     â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                                               â”‚   â”‚  â”‚
â”‚  â”‚  â”‚   3. ExecutionPipeline (Dynamic) â† WORKFLOW   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      â”œâ”€ ParallelAgent (if independent)        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      â”‚   sub_agents:                          â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      â”‚     - SecurityAgent â† SUB-AGENT        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      â”‚     - CodeQualityAgent â† SUB-AGENT     â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      â”‚     - EngineeringAgent â† SUB-AGENT     â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      â”‚     - CarbonAgent â† SUB-AGENT          â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      â”‚                                         â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      â””â”€ SequentialAgent (if dependent)        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚          sub_agents: [same as above]          â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                                               â”‚   â”‚  â”‚
â”‚  â”‚  â”‚   4. ReportSynthesizer (Agent) â† SUB-AGENT    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      Consolidates all analysis results        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                                               â”‚   â”‚  â”‚
â”‚  â”‚  â”‚   5. GitHubPublisher (Agent) â† SUB-AGENT      â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      Posts review to GitHub PR                â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚ WebPipeline (SequentialAgent) â† WORKFLOW     â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                                               â”‚   â”‚  â”‚
â”‚  â”‚  â”‚ sub_agents:                                   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚   1. ClassifierAgent (Agent) â† SUB-AGENT      â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      Classifies user intent                   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                                               â”‚   â”‚  â”‚
â”‚  â”‚  â”‚   2. PlanningAgent (Agent) â† SUB-AGENT        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      (same as GitHub pipeline)                â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                                               â”‚   â”‚  â”‚
â”‚  â”‚  â”‚   3. ExecutionPipeline (Dynamic) â† WORKFLOW   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      (same as GitHub pipeline)                â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                                               â”‚   â”‚  â”‚
â”‚  â”‚  â”‚   4. ReportSynthesizer (Agent) â† SUB-AGENT    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚      (same as GitHub pipeline)                â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  Step 7: MessageAcknowledger (FastAPI level)         â”‚  â”‚
â”‚  â”‚    â†“ ACK Pub/Sub message (removes from queue)        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

KEY LEGEND:
  SequentialAgent, ParallelAgent, LoopAgent = WORKFLOW CONTAINERS
  Agent = INDIVIDUAL SUB-AGENT (does actual work)
  
WORKFLOW HIERARCHY:
  Level 1: RootOrchestrator (SequentialAgent)
    Level 2: GitHubPipeline / WebPipeline (SequentialAgent)
      Level 3: ExecutionPipeline (ParallelAgent OR SequentialAgent)
        Level 4: SecurityAgent, CodeQualityAgent, etc. (Agent)
```

### Architecture Summary

**Workflow Agents (Containers):**
- `RootOrchestrator` (SequentialAgent) - Top-level workflow with routing
- `GitHubPipeline` (SequentialAgent) - GitHub webhook processing flow
- `WebPipeline` (SequentialAgent) - Web UI processing flow
- `ExecutionPipeline` (ParallelAgent OR SequentialAgent) - Dynamic analysis execution

**Sub-Agents (Workers):**
- `SourceDetector` - Determines request source
- `GitHubAgent` - Fetches PR data from GitHub
- `ClassifierAgent` - Classifies user intent
- `PlanningAgent` - Selects which analysis agents to run (uses PlanReActPlanner)
- `SecurityAgent` - Analyzes security vulnerabilities
- `CodeQualityAgent` - Analyzes code quality
- `EngineeringAgent` - Analyzes best practices
- `CarbonAgent` - Analyzes computational efficiency
- `ReportSynthesizer` - Consolidates results into report
- `GitHubPublisher` - Posts review to GitHub PR

**All of these are sub-agents!** They are ALL regular `Agent` instances, NOT workflow orchestrators. The only workflow containers are the SequentialAgent and ParallelAgent wrappers.

---

### Execution Flow (Step-by-Step)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RUNNER STARTS: runner.run_async(user_message, request_metadata)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: RootOrchestrator (SequentialAgent) starts                  â”‚
â”‚   â”œâ”€ Runs sub_agents[0] = SourceDetector (Agent)                   â”‚
â”‚   â”‚    Input: {user_message, request_metadata}                     â”‚
â”‚   â”‚    Output: {source: "github_webhook", github_context: {...}}   â”‚
â”‚   â”‚    Saves to: state["source_detection"]                         â”‚
â”‚   â”‚                                                                 â”‚
â”‚   â”œâ”€ Calls routing_function(context, state["source_detection"])    â”‚
â”‚   â”‚    Returns: "github_pipeline" or "web_pipeline"                â”‚
â”‚   â”‚                                                                 â”‚
â”‚   â””â”€ Selects dynamic_agents["github_pipeline"] or ["web_pipeline"] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼                        â–¼
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘ GITHUB WEBHOOK PATH   â•‘  â•‘ WEB UI PATH           â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                â”‚                        â”‚
                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: GitHubPipeline      â”‚ â”‚ STEP 2: WebPipeline         â”‚
â”‚ (SequentialAgent) starts    â”‚ â”‚ (SequentialAgent) starts    â”‚
â”‚                             â”‚ â”‚                             â”‚
â”‚ sub_agents[0] = GitHubAgent â”‚ â”‚ sub_agents[0] = Classifier  â”‚
â”‚   Input: {source_detection} â”‚ â”‚   Input: {user_message}     â”‚
â”‚   Calls: fetch_pr_files()   â”‚ â”‚   Output: {classification}  â”‚
â”‚   Output: {github_pr_data}  â”‚ â”‚   Saves to: state[]         â”‚
â”‚   Saves to: state[]         â”‚ â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                        â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: PlanningAgent (Agent) runs in BOTH pipelines               â”‚
â”‚   â”œâ”€ Has PlanReActPlanner                                          â”‚
â”‚   â”œâ”€ Has proxy tools: select_security_analysis, etc.               â”‚
â”‚   â”œâ”€ Input: {github_pr_data OR classification}                     â”‚
â”‚   â”œâ”€ LLM decides which agents to run                               â”‚
â”‚   â”œâ”€ Calls: select_security_analysis(), select_quality_analysis()  â”‚
â”‚   â”œâ”€ Output: {execution_plan: {                                    â”‚
â”‚   â”‚     selected_agents: ["security", "code_quality"],             â”‚
â”‚   â”‚     execution_mode: "parallel"                                 â”‚
â”‚   â”‚   }}                                                            â”‚
â”‚   â””â”€ Saves to: state["execution_plan"]                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: ExecutionPipeline (Dynamic) - CREATED AT RUNTIME           â”‚
â”‚   â”œâ”€ Code intercepts: if event.author == "PlanningAgent"           â”‚
â”‚   â”œâ”€ Reads: plan = state["execution_plan"]                         â”‚
â”‚   â”œâ”€ Creates: ParallelAgent OR SequentialAgent                     â”‚
â”‚   â”‚                                                                 â”‚
â”‚   â”œâ”€ IF execution_mode == "parallel":                              â”‚
â”‚   â”‚    ParallelAgent(                                               â”‚
â”‚   â”‚      sub_agents=[SecurityAgent, CodeQualityAgent, ...]         â”‚
â”‚   â”‚    )                                                            â”‚
â”‚   â”‚    â”œâ”€ SecurityAgent runs (in parallel)                         â”‚
â”‚   â”‚    â”‚   Output: {security_results}                              â”‚
â”‚   â”‚    â”œâ”€ CodeQualityAgent runs (in parallel)                      â”‚
â”‚   â”‚    â”‚   Output: {code_quality_results}                          â”‚
â”‚   â”‚    â””â”€ Results gathered when all complete                       â”‚
â”‚   â”‚                                                                 â”‚
â”‚   â””â”€ ELSE execution_mode == "sequential":                          â”‚
â”‚        SequentialAgent(                                             â”‚
â”‚          sub_agents=[SecurityAgent, CodeQualityAgent, ...]         â”‚
â”‚        )                                                            â”‚
â”‚        â”œâ”€ SecurityAgent runs first                                 â”‚
â”‚        â””â”€ CodeQualityAgent runs after                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: ReportSynthesizer (Agent) runs in BOTH pipelines           â”‚
â”‚   â”œâ”€ Input: {security_results, code_quality_results, ...}          â”‚
â”‚   â”œâ”€ LLM consolidates all findings                                 â”‚
â”‚   â”œâ”€ Output: {final_report: "# Code Review Report\n..."}           â”‚
â”‚   â””â”€ Saves to: state["final_report"]                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: GitHubPublisher     â”‚ â”‚ STEP 6: (No publisher)      â”‚
â”‚ (Agent) runs if GitHub      â”‚ â”‚ Report displayed in Web UI  â”‚
â”‚                             â”‚ â”‚                             â”‚
â”‚   Input: {final_report,     â”‚ â”‚                             â”‚
â”‚            github_context}  â”‚ â”‚                             â”‚
â”‚   Calls: post_review()      â”‚ â”‚                             â”‚
â”‚   Output: {review_url}      â”‚ â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                        â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WORKFLOW COMPLETE: All events yielded to caller                     â”‚
â”‚   Final state contains:                                             â”‚
â”‚   - source_detection                                                â”‚
â”‚   - github_pr_data (if GitHub) OR classification (if Web)           â”‚
â”‚   - execution_plan                                                  â”‚
â”‚   - security_results, code_quality_results, etc. (per plan)         â”‚
â”‚   - final_report                                                    â”‚
â”‚   - github_review_url (if GitHub)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Points:**

1. **SequentialAgent** runs sub-agents in ORDER (one after another)
2. **ParallelAgent** runs sub-agents SIMULTANEOUSLY (all at once)
3. **Dynamic routing** happens via `routing_function` after `SourceDetector`
4. **Dynamic execution** happens by intercepting events after `PlanningAgent`
5. **State passing** happens via `output_key` â†’ LLM instruction interpolation (`{key_name}`)
6. **All workflow agents** (Sequential, Parallel) are just containers - they don't do work themselves
7. **All actual work** is done by sub-agents (SourceDetector, GitHubAgent, SecurityAgent, etc.)

---

### Components Breakdown

#### 1. SourceDetector (Sub-Agent)

**Purpose:** Determine request source (GitHub webhook vs Web UI)

```python
source_detector = Agent(
    name="SourceDetector",
    model="gemini-2.5-flash",
    instruction="""Analyze the request context and determine the source.

Input Context:
- Request metadata: {request_metadata}
- User message: {user_message}
- Session state: {session_state}

Determine:
1. Is this from GitHub webhook? (Look for: pr_number, repo, head_sha)
2. Is this from Web UI? (Look for: interactive user message)
3. Other: General query or unknown source

Output JSON:
{
    "source": "github_webhook" | "web_ui" | "general_query",
    "confidence": 0.0-1.0,
    "reasoning": "Explanation",
    "github_context": {
        "repo": "owner/repo",
        "pr_number": 123,
        "head_sha": "abc123"
    } // Only if github_webhook
}""",
    output_key="source_detection"
)
```

#### 2. GitHubPipeline (SequentialAgent)

**Purpose:** Handle GitHub webhook requests with deterministic flow

```python
github_pipeline = SequentialAgent(
    name="GitHubPipeline",
    sub_agents=[
        github_agent,      # Fetch PR files and metadata
        classifier_agent,  # Classify changes (optional, could skip)
        # ... continues to planning
    ],
    description="Deterministic pipeline for GitHub PR review"
)
```

**github_agent** fetches PR data:

```python
# Three options for GitHub API integration with Google ADK:

# OPTION 1: Direct HTTP calls with requests/httpx (Simplest)
# âœ… Recommended for straightforward API calls
# No additional dependencies needed

import httpx

github_agent = Agent(
    name="GitHubAgent",
    model="gemini-2.5-flash",
    instruction="""Fetch PR files and metadata from GitHub.

GitHub Context: {source_detection.github_context}

I will help you make GitHub API calls. Based on the PR information, 
I'll construct the appropriate API requests and parse the responses.

You should ask me to:
1. Fetch PR files from: GET /repos/{owner}/{repo}/pulls/{pr_number}/files
2. Extract code changes (diff, additions, deletions)
3. Parse file paths, languages, and change statistics
4. Return structured data

Error Handling:
- If API fails, return error with details
- If no files changed, return empty list
""",
    output_key="github_pr_data"
)

# Then in your orchestrator or a custom tool:
async def fetch_github_pr_files(repo: str, pr_number: int, github_token: str):
    """Fetch PR files using direct HTTP calls."""
    url = f"https://api.github.com/repos/{repo}/pulls/{pr_number}/files"
    headers = {
        "Authorization": f"Bearer {github_token}",
        "Accept": "application/vnd.github+json",
        "X-GitHub-Api-Version": "2022-11-28"
    }
    
    async with httpx.AsyncClient() as client:
        response = await client.get(url, headers=headers)
        response.raise_for_status()
        return response.json()


# OPTION 2: PyGithub library (More features)
# âœ… Recommended if you need advanced GitHub features
# Install: pip install PyGithub
# Recommended for our project

from github import Github
from google.adk.tools import FunctionTool

def create_github_tools(github_token: str):
    """Create GitHub tools using PyGithub."""
    gh = Github(github_token)
    
    def fetch_pr_files(repo_name: str, pr_number: int) -> dict:
        """Fetch PR files and metadata."""
        repo = gh.get_repo(repo_name)
        pr = repo.get_pull(pr_number)
        
        files = []
        for file in pr.get_files():
            files.append({
                "filename": file.filename,
                "status": file.status,
                "additions": file.additions,
                "deletions": file.deletions,
                "changes": file.changes,
                "patch": file.patch  # The actual diff
            })
        
        return {
            "pr_number": pr.number,
            "title": pr.title,
            "body": pr.body,
            "state": pr.state,
            "files": files
        }
    
    def post_review_comment(repo_name: str, pr_number: int, body: str) -> dict:
        """Post review comment to PR."""
        repo = gh.get_repo(repo_name)
        pr = repo.get_pull(pr_number)
        review = pr.create_review(body=body, event="COMMENT")
        
        return {
            "review_id": review.id,
            "url": review.html_url
        }
    
    return [
        FunctionTool(
            name="fetch_github_pr_files",
            description="Fetch PR files and metadata from GitHub",
            function=fetch_pr_files
        ),
        FunctionTool(
            name="post_github_review",
            description="Post review comment to GitHub PR",
            function=post_review_comment
        )
    ]

github_tools = create_github_tools(os.getenv("GITHUB_TOKEN"))

github_agent = Agent(
    name="GitHubAgent",
    model="gemini-2.5-flash",
    tools=github_tools,
    instruction="""Fetch PR files and metadata from GitHub.

GitHub Context: {source_detection.github_context}

Use the fetch_github_pr_files tool to get PR data.

Tasks:
1. Call fetch_github_pr_files with repo and pr_number
2. Extract code changes from the response
3. Store in session state as github_pr_data

Error Handling:
- If tool call fails, return error with details
- If no files changed, return empty analysis
""",
    output_key="github_pr_data"
)


# OPTION 3: GitHub MCP Server (Most flexible)
# âœ… Recommended for complex GitHub workflows with multiple operations
# Uses Model Context Protocol for standardized GitHub access

from google.adk.mcp import MCPClient

# Configure GitHub MCP server (runs as separate process)
# See: https://github.com/modelcontextprotocol/servers/tree/main/src/github

github_mcp = MCPClient(
    command="npx",
    args=["-y", "@modelcontextprotocol/server-github"],
    env={"GITHUB_PERSONAL_ACCESS_TOKEN": os.getenv("GITHUB_TOKEN")}
)

github_agent = Agent(
    name="GitHubAgent",
    model="gemini-2.5-flash",
    tools=[github_mcp],  # MCP provides auto-discovered tools
    instruction="""Fetch PR files and metadata from GitHub using MCP tools.

GitHub Context: {source_detection.github_context}

Available MCP tools will include:
- get_pull_request: Get PR details
- list_pull_request_files: Get files changed in PR
- create_pull_request_review: Post review to PR

Tasks:
1. Use list_pull_request_files to get PR files
2. Extract code changes from the response
3. Store in session state as github_pr_data

Error Handling:
- If MCP tool fails, return error with details
- If no files changed, return empty analysis
""",
    output_key="github_pr_data"
)
```

**Recommendation for Google ADK:**

1. **For MVP/Simple Integration**: Use **Option 1** (direct HTTP with httpx)
   - Simple, no extra dependencies
   - Full control over API calls
   - Easy to debug

2. **For Production/Rich Features**: Use **Option 2** (PyGithub)
   - Well-maintained library with 6k+ stars
   - Handles pagination, rate limiting, authentication
   - Type-safe with good IDE support

3. **For Advanced Workflows**: Use **Option 3** (GitHub MCP)
   - Standardized interface for LLM-GitHub interaction
   - Auto-discovers available GitHub operations
   - Best for complex multi-step GitHub workflows

**None of these require Microsoft Agent Framework** - all work with **Google ADK** natively!

#### 3. ClassifierAgent (for Web UI path)

**Purpose:** Classify user intent when code is submitted via Web UI

```python
classifier_agent = Agent(
    name="ClassifierAgent",
    model="gemini-2.5-flash",
    instruction="""Classify user's code review request.

User Message: {user_message}

Analyze:
1. What type of review? (security, quality, practices, performance, comprehensive)
2. Is code present in message?
3. Specific focus areas mentioned?

Output JSON:
{
    "type": "code_review_security" | "code_review_quality" | "code_review_comprehensive",
    "has_code": true/false,
    "focus_areas": ["security", "authentication"],
    "confidence": 0.0-1.0
}""",
    output_key="classification"
)
```

#### 4. PlanningAgent (PlanReActPlanner)

**Purpose:** Intelligently determine which agents to execute and in what manner

```python
planning_agent = Agent(
    name="PlanningAgent",
    model="gemini-2.5-flash",
    planner=PlanReActPlanner(),
    tools=[
        # Proxy tools for agent selection
        FunctionTool(
            name="select_security_analysis",
            description="""Select Security Agent to analyze:
            - Vulnerabilities (SQL injection, XSS, CSRF)
            - Authentication/authorization issues
            - Input validation problems
            - Cryptography weaknesses
            
            Use when: Security concerns, vulnerabilities, exploits mentioned""",
            function=lambda: {"agent": "security"}
        ),
        FunctionTool(
            name="select_quality_analysis",
            description="""Select Code Quality Agent to analyze:
            - Cyclomatic complexity
            - Code maintainability
            - Code smells and anti-patterns
            - Duplication detection
            
            Use when: Quality, complexity, maintainability mentioned""",
            function=lambda: {"agent": "code_quality"}
        ),
        FunctionTool(
            name="select_practices_analysis",
            description="""Select Engineering Practices Agent to analyze:
            - SOLID principles compliance
            - Design pattern usage
            - Testing strategy
            - Documentation quality
            
            Use when: Best practices, SOLID, patterns mentioned""",
            function=lambda: {"agent": "engineering"}
        ),
        FunctionTool(
            name="select_carbon_analysis",
            description="""Select Carbon Emission Agent to analyze:
            - Computational efficiency
            - Algorithm optimization
            - Resource usage
            
            Use when: Performance, efficiency, optimization mentioned""",
            function=lambda: {"agent": "carbon"}
        ),
    ],
    instruction="""You are a code review planning agent.

Context:
- Source: {source_detection.source}
- GitHub Data: {github_pr_data}  // If from GitHub
- Classification: {classification}  // If from Web UI
- User Message: {user_message}

Your Task:
Analyze the request and intelligently select which analysis agents to employ.

<PLANNING>
1. Understand the request intent
2. Identify which analysis types are needed
3. Determine execution strategy (parallel vs sequential)
4. Consider dependencies between analyses
</PLANNING>

<REASONING>
- If user asks "review this code" with no specifics â†’ SELECT ALL agents (comprehensive)
- If user mentions specific area (e.g., "is this secure?") â†’ SELECT ONLY relevant agents
- If multiple areas mentioned â†’ SELECT MULTIPLE agents
- Consider whether analyses are independent (parallel) or dependent (sequential)
</REASONING>

<ACTION>
Call the appropriate select_*_analysis tools.
You can call multiple tools.
</ACTION>

<FINAL_ANSWER>
Output JSON:
{
    "selected_agents": ["security", "code_quality"],
    "execution_mode": "parallel" | "sequential",
    "reasoning": "Explanation of why these agents were selected",
    "estimated_duration": "2-5 minutes"
}
</FINAL_ANSWER>""",
    output_key="execution_plan"
)
```

#### 5. ExecutionPipeline (Dynamic: ParallelAgent or SequentialAgent)

**Purpose:** Execute selected agents based on planning decision

```python
def create_execution_pipeline(plan: dict) -> BaseAgent:
    """Create parallel or sequential pipeline based on plan."""
    
    agent_map = {
        "security": security_agent,
        "code_quality": code_quality_agent,
        "engineering": engineering_practices_agent,
        "carbon": carbon_emission_agent,
    }
    
    selected_agents = [agent_map[name] for name in plan["selected_agents"]]
    
    if plan["execution_mode"] == "parallel":
        return ParallelAgent(
            name="ParallelExecution",
            sub_agents=selected_agents,
            description="Execute independent analyses in parallel"
        )
    else:
        return SequentialAgent(
            name="SequentialExecution",
            sub_agents=selected_agents,
            description="Execute dependent analyses in sequence"
        )

# In main orchestrator
execution_pipeline = create_execution_pipeline(
    ctx.session.state["execution_plan"]
)

async for event in execution_pipeline.run_async(ctx):
    yield event
```

#### 6. ReportSynthesizer (LlmAgent)

**Purpose:** Consolidate results into final markdown report

```python
report_synthesizer = Agent(
    name="ReportSynthesizer",
    model="gemini-2.5-flash",
    instruction="""Synthesize comprehensive code review report.

Available Results:
- Security: {security_results}
- Quality: {code_quality_results}
- Practices: {engineering_results}
- Carbon: {carbon_results}

Execution Plan:
- Agents Run: {execution_plan.selected_agents}
- Reasoning: {execution_plan.reasoning}

Generate Markdown Report:

# Code Review Report

**Analysis ID:** {analysis_id}
**Date:** {timestamp}
**Source:** {source_detection.source}

## ğŸ§  Analysis Strategy

**Agents Selected:** {agents}
**Execution Mode:** {execution_mode}
**Reasoning:** {reasoning}

## ğŸ“Š Executive Summary

[Aggregate findings by severity]

## ğŸ” Detailed Findings

[Only include sections for agents that ran]

### ğŸ”’ Security Analysis
[If security_results exists]

### ğŸ“Š Code Quality
[If code_quality_results exists]

### âš™ï¸ Engineering Practices
[If engineering_results exists]

### ğŸŒ± Carbon Footprint
[If carbon_results exists]

## ğŸ’¡ Recommendations

[Prioritized action items]

---
*Powered by ADK Multi-Agent Code Review System*
""",
    output_key="final_report"
)
```

#### 7. GitHubPublisher (LlmAgent with GitHub Tools)

**Purpose:** Post review comments back to GitHub PR

```python
# Using the same GitHub integration approach as GitHubAgent

# OPTION 1: Direct HTTP (Simplest)
async def post_github_review(repo: str, pr_number: int, body: str, github_token: str):
    """Post review comment using direct HTTP."""
    url = f"https://api.github.com/repos/{repo}/pulls/{pr_number}/reviews"
    headers = {
        "Authorization": f"Bearer {github_token}",
        "Accept": "application/vnd.github+json",
        "X-GitHub-Api-Version": "2022-11-28"
    }
    payload = {
        "body": body,
        "event": "COMMENT"  # Options: COMMENT, APPROVE, REQUEST_CHANGES
    }
    
    async with httpx.AsyncClient() as client:
        response = await client.post(url, headers=headers, json=payload)
        response.raise_for_status()
        result = response.json()
        return result["html_url"]


# OPTION 2: PyGithub (Recommended)
# Uses the tools created in GitHubAgent section

github_publisher = Agent(
    name="GitHubPublisher",
    model="gemini-2.5-flash",
    tools=github_tools,  # Same tools from GitHubAgent
    instruction="""Post code review results to GitHub PR.

Report: {final_report}
GitHub Context: {source_detection.github_context}

Tasks:
1. Format report for GitHub markdown (already formatted)
2. Use post_github_review tool to post comment
3. Pass repo, pr_number, and report body
4. Store returned review URL in session state

Error Handling:
- If tool call fails, log error but don't fail the workflow
- User can manually view report in artifact storage
""",
    output_key="github_review_url"
)


# OPTION 3: GitHub MCP (Advanced)
# Uses the same MCP client from GitHubAgent

github_publisher = Agent(
    name="GitHubPublisher",
    model="gemini-2.5-flash",
    tools=[github_mcp],  # Same MCP client from GitHubAgent
    instruction="""Post code review results to GitHub PR using MCP.

Report: {final_report}
GitHub Context: {source_detection.github_context}

Tasks:
1. Format report for GitHub markdown (already formatted)
2. Use create_pull_request_review MCP tool
3. Set event type to "COMMENT"
4. Store returned review URL in session state

Error Handling:
- If MCP tool fails, log error but don't fail the workflow
- User can manually view report in artifact storage
""",
    output_key="github_review_url"
)
```

**Summary of Google ADK GitHub Integration:**

| Approach | Pros | Cons | Best For |
|----------|------|------|----------|
| **Direct HTTP (httpx)** | Simple, no deps, full control | More code, manual error handling | MVP, simple workflows |
| **PyGithub Library** | Feature-rich, well-maintained | Extra dependency | Production, most use cases |
| **GitHub MCP** | Standardized, auto-discovery | Requires Node.js runtime | Complex GitHub workflows |

**All three work perfectly with Google ADK!** No Microsoft Agent Framework needed.

#### 8. MessageAcknowledger (Pub/Sub Cleanup)

**Purpose:** Acknowledge Pub/Sub message to remove from queue and prevent reprocessing

```python
# This happens at the FastAPI endpoint level, not as an ADK agent

@app.post("/process")
async def process_code_review(request: Request):
    """Process code review from Pub/Sub push subscription."""
    
    envelope = await request.json()
    message_data = base64.b64decode(envelope["message"]["data"])
    payload = json.loads(message_data)
    
    try:
        # Run ADK orchestrator (Steps 1-6)
        async for event in orchestrator.run(...):
            pass
        
        # Step 7: Success - Return 200 OK to acknowledge message
        # Pub/Sub will remove message from queue
        logging.info(f"âœ… Completed PR #{payload['pr_number']} - ACKing message")
        return {"status": "success"}  # â† This ACKs the message
        
    except Exception as e:
        # Error - Return 500 to NACK message
        # Pub/Sub will retry (up to max_delivery_attempts)
        logging.error(f"âŒ Error processing PR #{payload['pr_number']}: {e}")
        raise HTTPException(status_code=500, detail=str(e))  # â† This NACKs
```

**How Pub/Sub Acknowledgment Works:**

1. **Success (HTTP 200-299):** Message is **acknowledged** and removed from queue
2. **Failure (HTTP 500-599):** Message is **not acknowledged** and will be retried
3. **Timeout (no response):** Message is **not acknowledged** and will be retried

**Configuration (Pub/Sub Subscription):**
```bash
gcloud pubsub subscriptions create code-review-worker-sub \
  --topic=code-review-queue \
  --push-endpoint=https://worker.example.com/process \
  --ack-deadline=600 \        # 10 minutes (code review can take time)
  --max-delivery-attempts=3 \  # Retry up to 3 times on failure
  --dead-letter-topic=code-review-dlq  # Failed messages go here
```

**Error Scenarios:**

| Scenario | HTTP Code | Pub/Sub Action | Explanation |
|----------|-----------|----------------|-------------|
| Success | 200 | ACK (remove from queue) | Review completed successfully |
| GitHub API failure (non-critical) | 200 | ACK (remove from queue) | Review done, GitHub post failed but logged |
| ADK orchestrator crash | 500 | NACK (retry) | Transient error, worth retrying |
| Invalid payload | 200 | ACK (remove from queue) | Permanent error, no point retrying |
| Timeout (>10min) | No response | NACK (retry) | Worker didn't respond in time |

**Why This Matters:**

âœ… **Prevents Duplicate Reviews:**
- Without ACK, same PR would be reviewed multiple times
- Wastes LLM tokens and GitHub API calls

âœ… **Enables Retries:**
- Transient errors (network issues) automatically retry
- Permanent errors (bad data) don't retry forever

âœ… **Dead Letter Queue:**
- After 3 failed attempts, message goes to DLQ
- Engineers can investigate and manually reprocess

---

## ğŸ”„ Complete Orchestrator Implementation

### ADK Workflow Architecture (Correct Pattern)

**Key Understanding from ADK Training:**

âœ… **SequentialAgent** = Container that runs sub-agents in order  
âœ… **ParallelAgent** = Container that runs sub-agents simultaneously  
âœ… **LoopAgent** = Container that runs sub-agents iteratively  
âœ… **sub_agents** = List of Agent instances (NOT workflow agents)  
âœ… **dynamic_agents** = Dict of workflow agents for conditional routing  

**Mental Model:**
```
RootOrchestrator (SequentialAgent)
â”‚
â”œâ”€ sub_agents: [SourceDetector]        â† Always runs first
â”‚
â””â”€ dynamic_agents: {                   â† Conditional routing
     'github_pipeline': GitHubPipeline (SequentialAgent)
                         â”œâ”€ GitHubAgent
                         â”œâ”€ PlanningAgent  
                         â”œâ”€ ExecutionPipeline (ParallelAgent OR SequentialAgent)
                         â”‚   â”œâ”€ SecurityAgent
                         â”‚   â”œâ”€ CodeQualityAgent
                         â”‚   â”œâ”€ EngineeringAgent
                         â”‚   â””â”€ CarbonAgent
                         â”œâ”€ ReportSynthesizer
                         â””â”€ GitHubPublisher
     
     'web_pipeline': WebPipeline (SequentialAgent)
                      â”œâ”€ ClassifierAgent
                      â”œâ”€ PlanningAgent
                      â”œâ”€ ExecutionPipeline (ParallelAgent OR SequentialAgent)
                      â”‚   â”œâ”€ SecurityAgent (if selected)
                      â”‚   â”œâ”€ CodeQualityAgent (if selected)
                      â”‚   â”œâ”€ EngineeringAgent (if selected)
                      â”‚   â””â”€ CarbonAgent (if selected)
                      â””â”€ ReportSynthesizer
   }
```

**CRITICAL:** SourceDetector, GitHubAgent, ClassifierAgent, PlanningAgent, ReportSynthesizer, GitHubPublisher are **ALL sub-agents** (regular Agent instances), NOT workflow orchestrators!

---

### RootOrchestrator Implementation

```python
# agent_workspace/orchestrator_agent/agent.py

from google.adk.agents import Agent, SequentialAgent, ParallelAgent
from google.adk.planners import PlanReActPlanner
from google.adk.tools import FunctionTool
from typing import Dict, Any

class RootOrchestrator:
    """
    Phase 2: ADK-native orchestrator using deterministic workflows.
    
    Pattern: SequentialAgent with conditional routing via Decision Framework
    
    Architecture:
    - RootOrchestrator = SequentialAgent (runs SourceDetector, then routes)
    - GitHubPipeline = SequentialAgent (runs github_agent â†’ planning â†’ execution â†’ report â†’ publish)
    - WebPipeline = SequentialAgent (runs classifier â†’ planning â†’ execution â†’ report)
    - ExecutionPipeline = ParallelAgent OR SequentialAgent (runs analysis agents based on plan)
    
    ALL agents (SourceDetector, GitHubAgent, Classifier, Planning, etc.) are sub-agents!
    """
    
    def __init__(self, github_token: str = None):
        """Initialize orchestrator with all sub-agents."""
        
        # =====================================================================
        # LEVEL 1: ROUTING SUB-AGENTS
        # =====================================================================
        
        self.source_detector = self._create_source_detector()
        
        # =====================================================================
        # LEVEL 2: PIPELINE-SPECIFIC SUB-AGENTS
        # =====================================================================
        
        # GitHub-specific agents
        self.github_agent = self._create_github_agent(github_token)
        self.github_publisher = self._create_github_publisher(github_token)
        
        # Web UI-specific agents
        self.classifier = self._create_classifier()
        
        # =====================================================================
        # LEVEL 3: SHARED SUB-AGENTS (used by both pipelines)
        # =====================================================================
        
        self.planning_agent = self._create_planning_agent()
        self.report_synthesizer = self._create_report_synthesizer()
        
        # =====================================================================
        # LEVEL 4: ANALYSIS SUB-AGENTS (selected dynamically by PlanningAgent)
        # =====================================================================
        
        self.security_agent = self._create_security_agent()
        self.code_quality_agent = self._create_code_quality_agent()
        self.engineering_agent = self._create_engineering_agent()
        self.carbon_agent = self._create_carbon_agent()
        
        # =====================================================================
        # WORKFLOW CONSTRUCTION
        # =====================================================================
        
        # Build nested workflow hierarchy
        self.root_agent = self._create_root_workflow()
    
    # =========================================================================
    # SUB-AGENT CREATION METHODS
    # =========================================================================
    
    def _create_source_detector(self) -> Agent:
        """
        Create source detection sub-agent.
        
        This is a regular Agent (NOT SequentialAgent), it runs first in the
        root workflow and determines which pipeline to route to.
        """
        return Agent(
            name="SourceDetector",
            model="gemini-2.5-flash",
            instruction="""Analyze the request context and determine the source.

Input Context:
- Request metadata: {request_metadata}
- User message: {user_message}

Determine:
1. Is this from GitHub webhook? (Look for: pr_number, repo, head_sha)
2. Is this from Web UI? (Look for: interactive user message)

Output JSON:
{
    "source": "github_webhook" | "web_ui",
    "confidence": 0.0-1.0,
    "reasoning": "Explanation",
    "github_context": {
        "repo": "owner/repo",
        "pr_number": 123,
        "head_sha": "abc123"
    }
}""",
            output_key="source_detection"
        )
    
    def _create_github_agent(self, github_token: str) -> Agent:
        """
        Create GitHub data fetching sub-agent.
        
        This is a regular Agent with GitHub tools, NOT a workflow agent.
        """
        from github import Github
        
        gh = Github(github_token)
        
        def fetch_pr_files(repo_name: str, pr_number: int) -> dict:
            """Fetch PR files and metadata."""
            repo = gh.get_repo(repo_name)
            pr = repo.get_pull(pr_number)
            
            files = []
            for file in pr.get_files():
                files.append({
                    "filename": file.filename,
                    "status": file.status,
                    "additions": file.additions,
                    "deletions": file.deletions,
                    "changes": file.changes,
                    "patch": file.patch
                })
            
            return {
                "pr_number": pr.number,
                "title": pr.title,
                "body": pr.body,
                "files": files
            }
        
        return Agent(
            name="GitHubAgent",
            model="gemini-2.5-flash",
            tools=[FunctionTool(
                name="fetch_pr_files",
                description="Fetch PR files and metadata from GitHub",
                function=fetch_pr_files
            )],
            instruction="""Fetch PR files and metadata from GitHub.

GitHub Context: {source_detection.github_context}

Tasks:
1. Call fetch_pr_files with repo and pr_number
2. Extract code changes from the response
3. Store in output as github_pr_data

Output: JSON with PR metadata and file changes""",
            output_key="github_pr_data"
        )
    
    def _create_classifier(self) -> Agent:
        """Create web UI classifier sub-agent."""
        return Agent(
            name="ClassifierAgent",
            model="gemini-2.5-flash",
            instruction="""Classify user's code review request.

User Message: {user_message}

Analyze:
1. What type of review? (security, quality, practices, performance, comprehensive)
2. Is code present in message?
3. Specific focus areas mentioned?

Output JSON:
{
    "type": "code_review_security" | "code_review_quality" | "code_review_comprehensive",
    "has_code": true/false,
    "focus_areas": ["security", "authentication"],
    "confidence": 0.0-1.0
}""",
            output_key="classification"
        )
    
    def _create_planning_agent(self) -> Agent:
        """
        Create planning sub-agent with Plan-ReAct planner.
        
        This agent uses proxy tools to "select" which analysis agents to run.
        The actual execution happens in ExecutionPipeline (Parallel or Sequential).
        """
        return Agent(
            name="PlanningAgent",
            model="gemini-2.5-flash",
            planner=PlanReActPlanner(),
            tools=[
                FunctionTool(
                    name="select_security_analysis",
                    description="""Select Security Agent to analyze vulnerabilities, authentication, 
                    input validation, cryptography. Use when: Security concerns mentioned.""",
                    function=lambda: {"agent": "security"}
                ),
                FunctionTool(
                    name="select_quality_analysis",
                    description="""Select Code Quality Agent to analyze complexity, maintainability, 
                    code smells. Use when: Quality, complexity mentioned.""",
                    function=lambda: {"agent": "code_quality"}
                ),
                FunctionTool(
                    name="select_practices_analysis",
                    description="""Select Engineering Practices Agent to analyze SOLID principles, 
                    design patterns, testing. Use when: Best practices mentioned.""",
                    function=lambda: {"agent": "engineering"}
                ),
                FunctionTool(
                    name="select_carbon_analysis",
                    description="""Select Carbon Emission Agent to analyze computational efficiency, 
                    algorithm optimization. Use when: Performance, efficiency mentioned.""",
                    function=lambda: {"agent": "carbon"}
                ),
            ],
            instruction="""You are a code review planning agent.

Context:
- Source: {source_detection.source}
- GitHub Data: {github_pr_data}  (if from GitHub)
- Classification: {classification}  (if from Web UI)

Your Task: Select which analysis agents to employ.

<PLANNING>
1. Understand the request intent
2. Identify which analysis types are needed
3. Determine execution strategy (parallel vs sequential)
</PLANNING>

<REASONING>
- If comprehensive review â†’ SELECT ALL agents
- If specific area mentioned â†’ SELECT ONLY relevant agents
- If multiple areas â†’ SELECT MULTIPLE agents
- Consider if analyses are independent (parallel) or dependent (sequential)
</REASONING>

<ACTION>
Call the appropriate select_*_analysis tools.
</ACTION>

<FINAL_ANSWER>
Output JSON:
{
    "selected_agents": ["security", "code_quality"],
    "execution_mode": "parallel" | "sequential",
    "reasoning": "Explanation"
}
</FINAL_ANSWER>""",
            output_key="execution_plan"
        )
    
    def _create_report_synthesizer(self) -> Agent:
        """Create report synthesizer sub-agent."""
        return Agent(
            name="ReportSynthesizer",
            model="gemini-2.5-flash",
            instruction="""Synthesize comprehensive code review report.

Available Results:
- Security: {security_results}
- Quality: {code_quality_results}
- Practices: {engineering_results}
- Carbon: {carbon_results}

Execution Plan: {execution_plan}

Generate Markdown Report with:
- Executive Summary
- Findings by severity
- Only include sections for agents that ran
- Prioritized recommendations""",
            output_key="final_report"
        )
    
    def _create_github_publisher(self, github_token: str) -> Agent:
        """Create GitHub publisher sub-agent."""
        from github import Github
        
        gh = Github(github_token)
        
        def post_review_comment(repo_name: str, pr_number: int, body: str) -> dict:
            """Post review comment to PR."""
            repo = gh.get_repo(repo_name)
            pr = repo.get_pull(pr_number)
            review = pr.create_review(body=body, event="COMMENT")
            
            return {
                "review_id": review.id,
                "url": review.html_url
            }
        
        return Agent(
            name="GitHubPublisher",
            model="gemini-2.5-flash",
            tools=[FunctionTool(
                name="post_github_review",
                description="Post review comment to GitHub PR",
                function=post_review_comment
            )],
            instruction="""Post code review results to GitHub PR.

Report: {final_report}
GitHub Context: {source_detection.github_context}

Tasks:
1. Use post_github_review tool to post comment
2. Pass repo, pr_number, and report body
3. Return review URL""",
            output_key="github_review_url"
        )
    
    def _create_security_agent(self) -> Agent:
        """Create security analysis sub-agent (reuse from Phase 1)."""
        # ... implementation from Phase 1
        return Agent(name="SecurityAgent", model="gemini-2.5-flash", ...)
    
    def _create_code_quality_agent(self) -> Agent:
        """Create code quality sub-agent (reuse from Phase 1)."""
        return Agent(name="CodeQualityAgent", model="gemini-2.5-flash", ...)
    
    def _create_engineering_agent(self) -> Agent:
        """Create engineering practices sub-agent (reuse from Phase 1)."""
        return Agent(name="EngineeringAgent", model="gemini-2.5-flash", ...)
    
    def _create_carbon_agent(self) -> Agent:
        """Create carbon emission sub-agent (reuse from Phase 1)."""
        return Agent(name="CarbonAgent", model="gemini-2.5-flash", ...)
    
    # =========================================================================
    # WORKFLOW CONSTRUCTION (NESTED SEQUENTIAL/PARALLEL AGENTS)
    # =========================================================================
    
    def _create_execution_pipeline(self, plan: Dict[str, Any]) -> "BaseAgent":
        """
        Create execution pipeline based on planning decision.
        
        Returns either ParallelAgent or SequentialAgent depending on plan.
        This is called DURING workflow execution, not during initialization.
        """
        agent_map = {
            "security": self.security_agent,
            "code_quality": self.code_quality_agent,
            "engineering": self.engineering_agent,
            "carbon": self.carbon_agent,
        }
        
        selected = [agent_map[name] for name in plan.get("selected_agents", [])]
        
        if plan.get("execution_mode") == "parallel":
            return ParallelAgent(
                name="ParallelExecution",
                sub_agents=selected,
                description="Execute independent analyses in parallel"
            )
        else:
            return SequentialAgent(
                name="SequentialExecution",
                sub_agents=selected,
                description="Execute dependent analyses in sequence"
            )
    
    def _create_root_workflow(self) -> SequentialAgent:
        """
        Create root orchestration workflow.
        
        Structure:
        RootOrchestrator (SequentialAgent)
          â””â”€ sub_agents: [SourceDetector]
          â””â”€ dynamic_agents: {
               'github_pipeline': SequentialAgent([github, planning, report, publish]),
               'web_pipeline': SequentialAgent([classifier, planning, report])
             }
          â””â”€ routing_function: route_by_source
        """
        
        # =====================================================================
        # ROUTING FUNCTION
        # =====================================================================
        
        def route_by_source(context, result):
            """
            Route to appropriate pipeline based on source detection.
            
            Args:
                context: ADK context with session state
                result: Output from SourceDetector agent (source_detection)
            
            Returns:
                str: Key name for dynamic_agents dict
            """
            source = result.get('source', 'web_ui')
            if source == 'github_webhook':
                return 'github_pipeline'
            else:
                return 'web_pipeline'
        
        # =====================================================================
        # GITHUB PIPELINE (SequentialAgent)
        # =====================================================================
        
        github_pipeline = SequentialAgent(
            name="GitHubPipeline",
            sub_agents=[
                self.github_agent,         # Step 1: Fetch PR data from GitHub
                self.planning_agent,       # Step 2: Plan which agents to run
                # Step 3: ExecutionPipeline (created dynamically based on plan)
                # NOTE: We handle this in the run() method by intercepting events
                self.report_synthesizer,   # Step 4: Synthesize final report
                self.github_publisher      # Step 5: Post review to GitHub PR
            ],
            description="GitHub webhook processing pipeline"
        )
        
        # =====================================================================
        # WEB UI PIPELINE (SequentialAgent)
        # =====================================================================
        
        web_pipeline = SequentialAgent(
            name="WebPipeline",
            sub_agents=[
                self.classifier,           # Step 1: Classify user intent
                self.planning_agent,       # Step 2: Plan which agents to run
                # Step 3: ExecutionPipeline (created dynamically based on plan)
                self.report_synthesizer    # Step 4: Synthesize final report
            ],
            description="Web UI request processing pipeline"
        )
        
        # =====================================================================
        # ROOT ORCHESTRATOR (SequentialAgent with Dynamic Routing)
        # =====================================================================
        
        return SequentialAgent(
            name="RootOrchestrator",
            sub_agents=[self.source_detector],  # Always runs first
            dynamic_agents={
                'github_pipeline': github_pipeline,  # Routed if source=github_webhook
                'web_pipeline': web_pipeline         # Routed if source=web_ui
            },
            routing_function=route_by_source,
            description="Root orchestrator with conditional pipeline routing"
        )
    
    # =========================================================================
    # EXECUTION METHOD
    # =========================================================================
    
    async def run(self, user_message: str, request_metadata: dict):
        """
        Run the orchestration workflow.
        
        Flow:
        1. SourceDetector runs â†’ determines source
        2. Routing function selects pipeline (github_pipeline or web_pipeline)
        3. Pipeline runs sequentially:
           - GitHub: github_agent â†’ planning â†’ [execution] â†’ report â†’ publish
           - Web: classifier â†’ planning â†’ [execution] â†’ report
        4. We intercept after PlanningAgent to dynamically create ExecutionPipeline
        """
        from google.adk.runners import Runner
        
        runner = Runner(agent=self.root_agent)
        
        async for event in runner.run_async(
            user_id="system",
            session_id=f"session_{request_metadata.get('pr_number', 'web')}",
            new_message=user_message,
            app_state={"request_metadata": request_metadata}
        ):
            # ================================================================
            # DYNAMIC EXECUTION INJECTION
            # ================================================================
            
            # After PlanningAgent completes, we need to inject ExecutionPipeline
            if event.author == "PlanningAgent" and event.turn_complete:
                # Get the plan from session state
                plan = event.context.session.state.get("execution_plan", {})
                
                # Create execution pipeline based on plan
                execution_pipeline = self._create_execution_pipeline(plan)
                
                # Run execution pipeline
                async for exec_event in execution_pipeline.run_async(event.context):
                    yield exec_event
            else:
                yield event
    
    def _create_execution_pipeline(self, plan: Dict[str, Any]) -> BaseAgent:
        """Create execution pipeline based on plan."""
        agent_map = {
            "security": self.security_agent,
            "code_quality": self.code_quality_agent,
            "engineering": self.engineering_agent,
            "carbon": self.carbon_agent,
        }
        
        selected = [agent_map[name] for name in plan.get("selected_agents", [])]
        
        if plan.get("execution_mode") == "parallel":
            return ParallelAgent(
                name="ParallelExecution",
                sub_agents=selected
            )
        else:
            return SequentialAgent(
                name="SequentialExecution",
                sub_agents=selected
            )
```

### FastAPI Worker Endpoint (Pub/Sub Integration)

```python
# worker.py - Cloud Run Worker Service entry point

from fastapi import FastAPI, Request, HTTPException
from google.cloud import logging as cloud_logging
import base64
import json
import logging

app = FastAPI()
orchestrator = RootOrchestrator()

# Setup Cloud Logging
cloud_logging.Client().setup_logging()
logger = logging.getLogger(__name__)

@app.post("/process")
async def process_code_review(request: Request):
    """
    Process code review from Pub/Sub push subscription.
    
    Pub/Sub Acknowledgment:
    - Return 200-299: Message is ACKed (removed from queue)
    - Return 500-599: Message is NACKed (will be retried)
    - No response: Message is NACKed after ack_deadline (600s)
    """
    
    # 1. Parse Pub/Sub message
    try:
        envelope = await request.json()
        message_data = base64.b64decode(envelope["message"]["data"])
        payload = json.loads(message_data)
        
        pr_number = payload.get("pr_number")
        repo = payload.get("repo")
        
        logger.info(f"ğŸ“¥ Received Pub/Sub message for {repo}#{pr_number}")
        
    except Exception as e:
        logger.error(f"âŒ Invalid Pub/Sub message format: {e}")
        # Return 200 to ACK - bad message, no point retrying
        return {"status": "rejected", "reason": "Invalid message format"}
    
    # 2. Run ADK orchestrator (Steps 1-6)
    try:
        logger.info(f"ğŸš€ Starting code review for {repo}#{pr_number}")
        
        async for event in orchestrator.run(
            user_message="",  # GitHub webhook, no user message
            request_metadata={
                "source": "github_webhook",
                "repo": repo,
                "pr_number": pr_number,
                "head_sha": payload.get("head_sha"),
                "action": payload.get("action")
            }
        ):
            # Log events for monitoring
            if event.turn_complete:
                logger.info(f"âœ“ Agent {event.author} completed")
        
        logger.info(f"âœ… Code review completed for {repo}#{pr_number}")
        
        # Step 7: Return 200 to ACK message (success)
        return {
            "status": "success",
            "pr_number": pr_number,
            "repo": repo
        }
        
    except GitHubAPIError as e:
        # GitHub API failures - Could be transient (rate limit, network)
        logger.error(f"âš ï¸ GitHub API error for {repo}#{pr_number}: {e}")
        
        if e.status_code == 403:  # Rate limit
            # Retry - might succeed after rate limit resets
            raise HTTPException(status_code=500, detail="GitHub rate limit")
        elif e.status_code == 404:  # PR not found
            # Don't retry - permanent error
            logger.warning(f"PR {repo}#{pr_number} not found, ACKing message")
            return {"status": "skipped", "reason": "PR not found"}
        else:
            # Unknown error - retry
            raise HTTPException(status_code=500, detail=str(e))
    
    except GeminiAPIError as e:
        # Gemini API failures - Usually transient
        logger.error(f"âš ï¸ Gemini API error for {repo}#{pr_number}: {e}")
        # Retry - might succeed on next attempt
        raise HTTPException(status_code=500, detail="LLM API error")
    
    except Exception as e:
        # Unexpected error
        logger.error(f"âŒ Unexpected error for {repo}#{pr_number}: {e}", exc_info=True)
        # Retry - might be transient
        raise HTTPException(status_code=500, detail="Internal error")

@app.get("/health")
async def health_check():
    """Health check endpoint for Cloud Run."""
    return {"status": "healthy"}

# Run with: uvicorn worker:app --host 0.0.0.0 --port 8080
```

**Key Points:**

1. **Success Path (200 OK):**
   - Code review completed successfully
   - GitHub review posted
   - Message is **ACKed** and removed from queue
   - Won't be processed again

2. **Transient Errors (500):**
   - API rate limits, network timeouts, temporary LLM issues
   - Message is **NACKed** and will be retried
   - Up to `max_delivery_attempts` (3 times)

3. **Permanent Errors (200 OK):**
   - Invalid message format, PR not found, bad data
   - Message is **ACKed** to remove from queue
   - No point retrying - would fail again

4. **Dead Letter Queue:**
   - After 3 failed retries, message goes to DLQ
   - Engineers can investigate and manually reprocess

---

## ğŸ§ª Testing Strategy

### Unit Tests

```python
@pytest.mark.asyncio
async def test_source_detector_identifies_github_webhook():
    """Test source detector correctly identifies GitHub webhook."""
    detector = create_source_detector()
    
    ctx = create_mock_context(
        user_message="",
        request_metadata={
            "pr_number": 123,
            "repo": "owner/repo",
            "head_sha": "abc123"
        }
    )
    
    async for event in detector.run_async(ctx):
        pass
    
    result = ctx.session.state["source_detection"]
    assert result["source"] == "github_webhook"
    assert result["github_context"]["pr_number"] == 123


@pytest.mark.asyncio
async def test_planning_agent_selects_security_for_security_query():
    """Test planning agent selects security agent for security focus."""
    planner = create_planning_agent()
    
    ctx = create_mock_context(
        user_message="Check if this code has SQL injection vulnerabilities",
        classification={"type": "code_review_security"}
    )
    
    async for event in planner.run_async(ctx):
        pass
    
    plan = ctx.session.state["execution_plan"]
    assert "security" in plan["selected_agents"]
    assert len(plan["selected_agents"]) == 1  # Only security needed
```

### Integration Tests

```python
@pytest.mark.asyncio
async def test_e2e_github_webhook_flow():
    """Test end-to-end flow from GitHub webhook to PR comment."""
    orchestrator = RootOrchestrator()
    
    events = []
    async for event in orchestrator.run(
        user_message="",
        request_metadata={
            "source": "github_webhook",
            "pr_number": 123,
            "repo": "test/repo",
            "head_sha": "abc123"
        }
    ):
        events.append(event)
    
    # Verify workflow
    assert any(e.author == "SourceDetector" for e in events)
    assert any(e.author == "GitHubAgent" for e in events)
    assert any(e.author == "PlanningAgent" for e in events)
    assert any(e.author == "ReportSynthesizer" for e in events)
    assert any(e.author == "GitHubPublisher" for e in events)
    
    # Verify GitHub review posted
    final_state = events[-1].context.session.state
    assert "github_review_url" in final_state
```

---

## ğŸš€ Deployment Architecture

### Cloud Run Services

```yaml
# api-service (Webhook Handler)
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: code-review-api
spec:
  template:
    spec:
      containers:
      - image: gcr.io/project/code-review-api:latest
        env:
        - name: PUBSUB_TOPIC
          value: projects/PROJECT_ID/topics/code-review-queue
        resources:
          limits:
            memory: 512Mi
            cpu: 1

# worker-service (ADK Orchestrator)
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: code-review-worker
spec:
  template:
    spec:
      containers:
      - image: gcr.io/project/code-review-worker:latest
        env:
        - name: GOOGLE_API_KEY
          valueFrom:
            secretKeyRef:
              name: gemini-api-key
              key: key
        - name: GITHUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: github-token
              key: token
        resources:
          limits:
            memory: 2Gi
            cpu: 2
```

### Cloud Pub/Sub Configuration

```bash
# Create topic
gcloud pubsub topics create code-review-queue

# Create subscription with push to worker
gcloud pubsub subscriptions create code-review-worker-sub \
  --topic=code-review-queue \
  --push-endpoint=https://code-review-worker-HASH-uc.a.run.app/process \
  --ack-deadline=600 \
  --max-delivery-attempts=3
```

---

## ğŸ”§ GitHub Integration: Personal vs Organization vs Enterprise

### Architecture Decision: GitHub Apps vs Personal Access Tokens

| Approach | Best For | Pros | Cons |
|----------|----------|------|------|
| **Personal Access Token (PAT)** | Personal repos, single user | Simple setup, no OAuth | Tied to user account, limited to 60 req/hr |
| **GitHub App (Recommended)** | Organizations, multiple repos | Fine-grained permissions, 5000 req/hr, org-level install | Complex setup, requires OAuth flow |
| **GitHub App + Installation Tokens** | Enterprise, multi-tenant SaaS | Per-repo authentication, auto-revocation, audit logs | Most complex, requires database |

**Recommendation:**
- **MVP (Personal Use):** Personal Access Token âœ… Simple
- **Production (Organization):** GitHub App âœ… Recommended
- **Enterprise (Multi-tenant SaaS):** GitHub App + Installation Tokens âœ… Scalable

---

## ğŸ¢ Multi-Tenant Architecture Design

### Database Schema for Multi-Tenant Support

```sql
-- Organizations/Tenants table
CREATE TABLE organizations (
    org_id UUID PRIMARY KEY,
    github_org_name VARCHAR(255) UNIQUE NOT NULL,  -- e.g., "microsoft", "google"
    github_org_id BIGINT UNIQUE NOT NULL,           -- GitHub's org ID
    subscription_tier VARCHAR(50),                  -- free, pro, enterprise
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- GitHub App installations (per org/user)
CREATE TABLE github_installations (
    installation_id BIGINT PRIMARY KEY,             -- GitHub's installation ID
    org_id UUID REFERENCES organizations(org_id),
    installation_type VARCHAR(20),                  -- 'organization' or 'user'
    github_account_name VARCHAR(255),               -- org/user name
    github_account_id BIGINT,                       -- org/user ID
    installed_at TIMESTAMP,
    suspended_at TIMESTAMP NULL,
    INDEX idx_org_installation (org_id, installation_id)
);

-- Repository configurations (per repo)
CREATE TABLE repositories (
    repo_id UUID PRIMARY KEY,
    installation_id BIGINT REFERENCES github_installations(installation_id),
    github_repo_id BIGINT UNIQUE NOT NULL,          -- GitHub's repo ID
    full_name VARCHAR(255) UNIQUE NOT NULL,         -- "owner/repo"
    webhook_secret_name VARCHAR(255),               -- GCP Secret Manager reference
    is_active BOOLEAN DEFAULT TRUE,
    config JSONB,                                   -- Per-repo settings
    created_at TIMESTAMP DEFAULT NOW(),
    INDEX idx_installation_repo (installation_id, github_repo_id),
    INDEX idx_full_name (full_name)
);

-- Code review sessions (multi-tenant)
CREATE TABLE review_sessions (
    session_id UUID PRIMARY KEY,
    repo_id UUID REFERENCES repositories(repo_id),
    pr_number INTEGER NOT NULL,
    github_pr_id BIGINT NOT NULL,
    head_sha VARCHAR(40),
    author_login VARCHAR(255),
    status VARCHAR(50),                             -- pending, in_progress, completed, failed
    analysis_id VARCHAR(100),
    artifact_path VARCHAR(500),                     -- GCS path to artifacts
    created_at TIMESTAMP DEFAULT NOW(),
    completed_at TIMESTAMP NULL,
    INDEX idx_repo_pr (repo_id, pr_number),
    INDEX idx_status (status, created_at)
);

-- Audit logs (compliance)
CREATE TABLE audit_logs (
    log_id UUID PRIMARY KEY,
    org_id UUID REFERENCES organizations(org_id),
    repo_id UUID REFERENCES repositories(repo_id) NULL,
    actor VARCHAR(255),                             -- User who triggered action
    action VARCHAR(100),                            -- webhook_received, review_posted, etc.
    details JSONB,
    timestamp TIMESTAMP DEFAULT NOW(),
    INDEX idx_org_timestamp (org_id, timestamp),
    INDEX idx_repo_timestamp (repo_id, timestamp)
);
```

### Enhanced Webhook Payload Processing

```python
# api_server.py - Multi-tenant webhook handler

from fastapi import FastAPI, Request, HTTPException, Header
from typing import Optional
import hmac
import hashlib

app = FastAPI()

class RepositoryService:
    """Service to fetch repository-specific configuration."""
    
    async def get_repo_config(self, github_repo_id: int) -> dict:
        """
        Fetch repository configuration from database.
        
        Returns:
        {
            "repo_id": "uuid",
            "installation_id": 12345,
            "webhook_secret": "secret_from_secret_manager",
            "org_id": "uuid",
            "config": {"max_files": 100, "auto_approve": false}
        }
        """
        # Query database
        query = """
            SELECT 
                r.repo_id,
                r.installation_id,
                r.webhook_secret_name,
                r.config,
                gi.org_id,
                o.subscription_tier
            FROM repositories r
            JOIN github_installations gi ON r.installation_id = gi.installation_id
            JOIN organizations o ON gi.org_id = o.org_id
            WHERE r.github_repo_id = $1 AND r.is_active = TRUE
        """
        result = await db.fetchrow(query, github_repo_id)
        
        if not result:
            raise ValueError(f"Repository {github_repo_id} not configured")
        
        # Fetch webhook secret from Secret Manager
        from google.cloud import secretmanager
        client = secretmanager.SecretManagerServiceClient()
        secret_name = f"projects/{PROJECT_ID}/secrets/{result['webhook_secret_name']}/versions/latest"
        response = client.access_secret_version(request={"name": secret_name})
        webhook_secret = response.payload.data.decode('UTF-8')
        
        return {
            "repo_id": result["repo_id"],
            "installation_id": result["installation_id"],
            "webhook_secret": webhook_secret,
            "org_id": result["org_id"],
            "subscription_tier": result["subscription_tier"],
            "config": result["config"]
        }

repo_service = RepositoryService()


@app.post("/webhook/github")
async def github_webhook(
    request: Request,
    x_hub_signature_256: Optional[str] = Header(None),
    x_github_event: Optional[str] = Header(None),
    x_github_delivery: Optional[str] = Header(None)
):
    """
    Multi-tenant GitHub webhook handler.
    
    Flow:
    1. Extract repository from payload
    2. Fetch repo-specific webhook secret from database
    3. Validate HMAC signature with repo-specific secret
    4. Fetch GitHub App installation token for this repo
    5. Enrich payload with tenant context
    6. Publish to Pub/Sub with tenant isolation
    """
    
    # 1. Read raw body (needed for HMAC validation)
    body = await request.body()
    
    # 2. Parse payload to get repository
    try:
        payload = json.loads(body)
    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="Invalid JSON")
    
    # 3. Extract repository information
    if "repository" not in payload:
        raise HTTPException(status_code=400, detail="Missing repository in payload")
    
    github_repo_id = payload["repository"]["id"]
    repo_full_name = payload["repository"]["full_name"]
    
    logger.info(f"ğŸ“¥ Webhook received for {repo_full_name} (ID: {github_repo_id})")
    
    # 4. Fetch repository-specific configuration (includes webhook secret)
    try:
        repo_config = await repo_service.get_repo_config(github_repo_id)
    except ValueError as e:
        logger.warning(f"âš ï¸ Repository {repo_full_name} not configured: {e}")
        # Return 200 to avoid GitHub retrying for unconfigured repos
        return {"status": "ignored", "reason": "Repository not configured in system"}
    
    # 5. Validate HMAC signature with repo-specific secret
    if not x_hub_signature_256:
        raise HTTPException(status_code=401, detail="Missing X-Hub-Signature-256 header")
    
    expected_signature = "sha256=" + hmac.new(
        repo_config["webhook_secret"].encode(),
        body,
        hashlib.sha256
    ).hexdigest()
    
    if not hmac.compare_digest(x_hub_signature_256, expected_signature):
        logger.error(f"âŒ Invalid signature for {repo_full_name}")
        # Audit log for security
        await audit_log(
            org_id=repo_config["org_id"],
            repo_id=repo_config["repo_id"],
            action="webhook_signature_failed",
            details={"repo": repo_full_name, "event": x_github_event}
        )
        raise HTTPException(status_code=401, detail="Invalid signature")
    
    # 6. Filter: Only process PR events
    if x_github_event != "pull_request":
        return {"status": "ignored", "reason": f"Event '{x_github_event}' not processed"}
    
    action = payload.get("action")
    if action not in ["opened", "synchronize", "reopened"]:
        return {"status": "ignored", "reason": f"PR action '{action}' not processed"}
    
    # 7. Fetch GitHub App installation token (short-lived, repo-specific)
    installation_token = await get_installation_token(
        installation_id=repo_config["installation_id"]
    )
    
    # 8. Extract PR data with tenant context
    pr = payload["pull_request"]
    enriched_payload = {
        # Tenant context (CRITICAL for multi-tenant isolation)
        "org_id": repo_config["org_id"],
        "repo_id": repo_config["repo_id"],
        "installation_id": repo_config["installation_id"],
        "subscription_tier": repo_config["subscription_tier"],
        
        # GitHub context
        "repo": repo_full_name,
        "github_repo_id": github_repo_id,
        "pr_number": pr["number"],
        "github_pr_id": pr["id"],
        "head_sha": pr["head"]["sha"],
        "action": action,
        "title": pr["title"],
        "author": pr["user"]["login"],
        
        # Authentication (short-lived installation token)
        "github_token": installation_token,  # Valid for 1 hour
        
        # Webhook metadata
        "webhook_delivery_id": x_github_delivery,
        "webhook_event": x_github_event,
        
        # Repo-specific config
        "repo_config": repo_config["config"],
        
        # Timestamps
        "webhook_received_at": datetime.utcnow().isoformat()
    }
    
    # 9. Create review session record
    session_id = str(uuid.uuid4())
    await db.execute("""
        INSERT INTO review_sessions (
            session_id, repo_id, pr_number, github_pr_id, 
            head_sha, author_login, status
        )
        VALUES ($1, $2, $3, $4, $5, $6, 'pending')
    """, session_id, repo_config["repo_id"], pr["number"], 
         pr["id"], pr["head"]["sha"], pr["user"]["login"])
    
    enriched_payload["session_id"] = session_id
    
    # 10. Publish to Pub/Sub with tenant routing
    from google.cloud import pubsub_v1
    
    publisher = pubsub_v1.PublisherClient()
    
    # Use org-specific topic for tenant isolation (optional)
    # OR use single topic with tenant attribute for filtering
    topic_path = f"projects/{PROJECT_ID}/topics/code-review-queue"
    
    message_data = json.dumps(enriched_payload).encode()
    
    # Add tenant attributes for Pub/Sub filtering/routing
    future = publisher.publish(
        topic_path,
        message_data,
        org_id=repo_config["org_id"],              # For filtering
        repo_id=repo_config["repo_id"],            # For filtering
        subscription_tier=repo_config["subscription_tier"]  # For priority routing
    )
    message_id = future.result()
    
    # 11. Audit log
    await audit_log(
        org_id=repo_config["org_id"],
        repo_id=repo_config["repo_id"],
        actor=pr["user"]["login"],
        action="webhook_accepted",
        details={
            "pr_number": pr["number"],
            "message_id": message_id,
            "session_id": session_id
        }
    )
    
    logger.info(f"âœ… Published PR #{pr['number']} for {repo_full_name} to queue: {message_id}")
    
    # 12. Return fast ACK to GitHub
    return {
        "status": "accepted",
        "session_id": session_id,
        "message_id": message_id,
        "pr_number": pr["number"]
    }


async def get_installation_token(installation_id: int) -> str:
    """
    Get GitHub App installation token for specific installation.
    
    This token is:
    - Short-lived (1 hour)
    - Repository-specific (based on installation)
    - Auto-revoked when app uninstalled
    - Higher rate limits (5000 req/hr)
    
    Returns: Installation access token
    """
    import jwt
    import time
    import httpx
    
    # 1. Generate JWT for GitHub App authentication
    # (GitHub App private key stored in Secret Manager)
    from google.cloud import secretmanager
    client = secretmanager.SecretManagerServiceClient()
    private_key_name = f"projects/{PROJECT_ID}/secrets/github-app-private-key/versions/latest"
    response = client.access_secret_version(request={"name": private_key_name})
    private_key = response.payload.data.decode('UTF-8')
    
    # GitHub App ID (from environment)
    app_id = os.getenv("GITHUB_APP_ID")
    
    # Create JWT (valid for 10 minutes)
    now = int(time.time())
    payload = {
        "iat": now - 60,        # Issued at (with 60s clock skew)
        "exp": now + 600,       # Expires in 10 minutes
        "iss": app_id           # GitHub App ID
    }
    
    jwt_token = jwt.encode(payload, private_key, algorithm="RS256")
    
    # 2. Exchange JWT for installation access token
    url = f"https://api.github.com/app/installations/{installation_id}/access_tokens"
    headers = {
        "Authorization": f"Bearer {jwt_token}",
        "Accept": "application/vnd.github+json",
        "X-GitHub-Api-Version": "2022-11-28"
    }
    
    async with httpx.AsyncClient() as client:
        response = await client.post(url, headers=headers)
        response.raise_for_status()
        data = response.json()
        
        # Token is valid for 1 hour
        # Cache it with expiration
        installation_token = data["token"]
        expires_at = data["expires_at"]  # ISO 8601 timestamp
        
        # Optional: Cache in Redis/Memcached to avoid repeated JWT exchanges
        # await cache.set(f"github_token:{installation_id}", installation_token, ttl=3000)
        
        return installation_token


async def audit_log(org_id: str, repo_id: str, actor: str, action: str, details: dict):
    """Write audit log for compliance."""
    await db.execute("""
        INSERT INTO audit_logs (log_id, org_id, repo_id, actor, action, details)
        VALUES ($1, $2, $3, $4, $5, $6)
    """, str(uuid.uuid4()), org_id, repo_id, actor, action, json.dumps(details))
```

---

## ğŸ”‘ GitHub App Setup (Recommended for Organizations)

### Step 1: Create GitHub App

**Purpose:** Organization-level installation with fine-grained permissions

1. **Go to:** https://github.com/organizations/YOUR_ORG/settings/apps/new
   - Or personal: https://github.com/settings/apps/new

2. **GitHub App Configuration:**
   
   **Basic Information:**
   ```
   GitHub App name: Agentic Code Review Bot
   Homepage URL: https://your-company.com/code-review
   Webhook URL: https://code-review-api-HASH-uc.a.run.app/webhook/github
   Webhook secret: (generate with: openssl rand -hex 32)
   ```
   
   **Permissions (Repository):**
   ```
   âœ… Pull requests: Read & write
   âœ… Contents: Read-only
   âœ… Metadata: Read-only (automatically selected)
   ```
   
   **Subscribe to events:**
   ```
   âœ… Pull request
       - opened
       - reopened  
       - synchronize
   ```
   
   **Where can this GitHub App be installed?**
   ```
   â—‹ Only on this account (private)
   â— Any account (public - if building SaaS)
   ```

3. **Click:** "Create GitHub App"

4. **Generate Private Key:**
   - Scroll to "Private keys" section
   - Click "Generate a private key"
   - Download `your-app-name.2025-11-30.private-key.pem`
   - Store securely:
     ```bash
     # Store in Google Secret Manager
     gcloud secrets create github-app-private-key \
       --data-file=your-app-name.2025-11-30.private-key.pem
     
     # Delete local copy
     rm your-app-name.2025-11-30.private-key.pem
     ```

5. **Note App ID:**
   - Found at top of page: `App ID: 123456`
   - Store in environment:
     ```bash
     export GITHUB_APP_ID=123456
     
     # Cloud Run
     gcloud secrets create github-app-id --data-file=- <<< "123456"
     ```

### Step 2: Install GitHub App on Organization/Repositories

**Purpose:** Grant app access to specific repositories

1. **Go to:** https://github.com/organizations/YOUR_ORG/settings/installations

2. **Click:** "Install App" â†’ Select your app

3. **Choose repositories:**
   ```
   â—‹ All repositories (risky, not recommended)
   â— Only select repositories:
       â˜‘ repo-1
       â˜‘ repo-2
       â˜‘ repo-3
   ```

4. **Click:** "Install"

5. **Note Installation ID:**
   - After install, URL will be: `https://github.com/organizations/YOUR_ORG/settings/installations/12345678`
   - Installation ID: `12345678`
   - Store in database (repositories table)

### Step 3: Register Installation in Database

```bash
# Insert organization
psql -h DB_HOST -U postgres -d codereview -c "
INSERT INTO organizations (org_id, github_org_name, github_org_id, subscription_tier)
VALUES (
    'uuid-here',
    'your-org-name',
    123456,  -- GitHub org ID (from API or org settings)
    'enterprise'
);"

# Insert GitHub App installation
psql -h DB_HOST -U postgres -d codereview -c "
INSERT INTO github_installations (
    installation_id, org_id, installation_type, 
    github_account_name, github_account_id, installed_at
)
VALUES (
    12345678,                -- Installation ID from Step 2
    'uuid-here',            -- org_id from above
    'organization',
    'your-org-name',
    123456,                 -- GitHub org ID
    NOW()
);"

# Register repositories (repeat for each repo)
psql -h DB_HOST -U postgres -d codereview -c "
INSERT INTO repositories (
    repo_id, installation_id, github_repo_id, 
    full_name, webhook_secret_name, is_active, config
)
VALUES (
    gen_random_uuid(),
    12345678,                           -- Installation ID
    987654321,                          -- GitHub repo ID
    'your-org-name/repo-1',
    'webhook-secret-org-repo1',         -- Secret Manager reference
    TRUE,
    '{\"max_files\": 100, \"auto_approve\": false}'::jsonb
);"

# Store webhook secret in Secret Manager (per repo)
openssl rand -hex 32 | gcloud secrets create webhook-secret-org-repo1 --data-file=-
```

### Step 4: Configure Webhooks (Per Repository)

**Note:** When using GitHub Apps, webhooks are auto-configured at installation!

If manual configuration needed:
1. Go to: https://github.com/YOUR_ORG/REPO/settings/hooks
2. Verify webhook exists with correct URL
3. Check "Recent Deliveries" for successful pings

---

## ğŸ”’ Security & Compliance for Enterprise

### Data Isolation

```python
# worker.py - Ensure tenant isolation

@app.post("/process")
async def process_code_review(request: Request):
    """Process code review with tenant isolation."""
    
    envelope = await request.json()
    message_data = base64.b64decode(envelope["message"]["data"])
    payload = json.loads(message_data)
    
    # Extract tenant context
    org_id = payload["org_id"]
    repo_id = payload["repo_id"]
    session_id = payload["session_id"]
    
    # Create tenant-scoped storage path
    artifact_base_path = f"gs://{BUCKET_NAME}/{org_id}/{repo_id}/{session_id}"
    
    # Configure artifact service with tenant isolation
    artifact_service = FileArtifactService(base_path=artifact_base_path)
    
    # Run orchestrator with tenant context
    async for event in orchestrator.run(
        user_message="",
        request_metadata={
            "org_id": org_id,          # CRITICAL: Tenant isolation
            "repo_id": repo_id,
            "session_id": session_id,
            "github_token": payload["github_token"],  # Repo-specific token
            **payload
        },
        artifact_service=artifact_service  # Tenant-scoped storage
    ):
        pass
    
    # Update session status
    await db.execute("""
        UPDATE review_sessions
        SET status = 'completed', completed_at = NOW()
        WHERE session_id = $1 AND repo_id = $2
    """, session_id, repo_id)  # Double-check tenant boundary
    
    return {"status": "success", "session_id": session_id}
```

### Access Control

```python
# Verify user can access review results

@app.get("/api/reviews/{session_id}")
async def get_review(
    session_id: str,
    current_user: User = Depends(get_current_user)  # JWT auth
):
    """Get review results with access control."""
    
    # Fetch review session
    session = await db.fetchrow("""
        SELECT rs.*, r.installation_id, gi.org_id
        FROM review_sessions rs
        JOIN repositories r ON rs.repo_id = r.repo_id
        JOIN github_installations gi ON r.installation_id = gi.installation_id
        WHERE rs.session_id = $1
    """, session_id)
    
    if not session:
        raise HTTPException(status_code=404, detail="Review not found")
    
    # Verify user has access to this org
    user_orgs = await get_user_organizations(current_user.github_id)
    if session["org_id"] not in user_orgs:
        raise HTTPException(status_code=403, detail="Access denied")
    
    # Fetch artifacts from tenant-scoped storage
    artifact_path = f"gs://{BUCKET_NAME}/{session['org_id']}/{session['repo_id']}/{session_id}/reports/final_report.md"
    
    return {
        "session_id": session_id,
        "status": session["status"],
        "report_url": artifact_path
    }
```

### Rate Limiting (Per Organization)

```python
# Pub/Sub subscription with org-specific filtering

# Create separate subscriptions for different tiers
gcloud pubsub subscriptions create code-review-worker-free \
  --topic=code-review-queue \
  --push-endpoint=https://worker.example.com/process \
  --ack-deadline=600 \
  --filter='attributes.subscription_tier="free"' \
  --max-delivery-rate=10  # 10 reviews/minute for free tier

gcloud pubsub subscriptions create code-review-worker-enterprise \
  --topic=code-review-queue \
  --push-endpoint=https://worker-premium.example.com/process \
  --ack-deadline=600 \
  --filter='attributes.subscription_tier="enterprise"' \
  --max-delivery-rate=1000  # 1000 reviews/minute for enterprise
```

---

## ğŸ“‹ Personal vs Organization Setup Comparison

| Aspect | Personal Account | Organization Account | Enterprise Multi-Tenant |
|--------|------------------|----------------------|-------------------------|
| **Authentication** | Personal Access Token | GitHub App (org-level) | GitHub App + Installation Tokens |
| **Webhook Secret** | Single global secret | Per-organization secret | Per-repository secret |
| **Rate Limits** | 60 req/hr (or 5000 if authed) | 5000 req/hr per installation | 5000 req/hr per installation |
| **Permissions** | User's personal permissions | Fine-grained app permissions | Fine-grained app permissions |
| **Token Lifetime** | 90 days (manual refresh) | 1 hour (auto-refresh) | 1 hour (auto-refresh) |
| **Revocation** | Manual token deletion | Auto-revoked on app uninstall | Auto-revoked on app uninstall |
| **Audit Logs** | None | Basic GitHub logs | Full audit trail in database |
| **Data Isolation** | Single user | Per-org storage | Per-org + per-repo storage |
| **Cost** | Free | Free | Database + storage costs |
| **Setup Complexity** | â­ Simple | â­â­ Moderate | â­â­â­ Complex |
| **Best For** | Learning, personal projects | Teams, private repos | SaaS product, multi-tenant |

---

## ğŸš€ Migration Path: Personal â†’ Organization â†’ Enterprise

### Phase 1: Personal (MVP) âœ… Current Design
- Use Personal Access Token
- Single webhook secret
- No database needed
- Perfect for testing and learning

### Phase 2: Organization (Production)
- Create GitHub App
- Install on organization
- Add database for installation tracking
- Per-org webhook secrets
- **Backward compatible** with Phase 1 (keep PAT as fallback)

### Phase 3: Enterprise (Multi-Tenant SaaS)
- Full database schema (see above)
- Per-repository webhook secrets
- Tenant-scoped storage (GCS with org/repo prefixes)
- Rate limiting per subscription tier
- Audit logging and compliance
- User authentication (OAuth, JWT)
- Web dashboard for managing installations

**Good news:** The ADK orchestrator code doesn't change! Only webhook handler and storage paths need updates.

---

### Step 2: Configure Repository Webhook

**Purpose:** GitHub sends webhook events when PRs are opened/updated

#### 2.1 Deploy Your API Service First

Before configuring the webhook, deploy your API service to get the URL:

```bash
# Deploy API service to Cloud Run
gcloud run deploy code-review-api \
  --image gcr.io/PROJECT_ID/code-review-api:latest \
  --region us-central1 \
  --allow-unauthenticated

# Get the service URL
gcloud run services describe code-review-api \
  --region us-central1 \
  --format='value(status.url)'
# Output: https://code-review-api-HASH-uc.a.run.app
```

#### 2.2 Generate Webhook Secret

```bash
# Generate a secure random secret (32 bytes, hex encoded)
openssl rand -hex 32

# Example output: a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6q7r8s9t0u1v2w3x4y5z6a7b8c9d0e1f2

# Store it securely
export GITHUB_WEBHOOK_SECRET="a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6q7r8s9t0u1v2w3x4y5z6a7b8c9d0e1f2"

# Add to Cloud Run secret
gcloud secrets create github-webhook-secret \
  --data-file=- <<< "$GITHUB_WEBHOOK_SECRET"
```

#### 2.3 Configure Webhook in GitHub Repository

1. **Go to your repository:** https://github.com/rahulgupta2018/YOUR_REPO

2. **Navigate to:** Settings â†’ Webhooks â†’ "Add webhook"

3. **Webhook Configuration:**
   
   **Payload URL:**
   ```
   https://code-review-api-HASH-uc.a.run.app/webhook/github
   ```
   
   **Content type:**
   ```
   application/json
   ```
   
   **Secret:**
   ```
   a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6q7r8s9t0u1v2w3x4y5z6a7b8c9d0e1f2
   ```
   (Use the secret generated in Step 2.2)
   
   **Which events would you like to trigger this webhook?**
   ```
   â˜ Just the push event
   â˜‘ Let me select individual events:
       â˜‘ Pull requests
           - opened
           - reopened
           - synchronize (new commits pushed)
           - edited
       â˜ Pushes (uncheck)
       â˜ Issues (uncheck)
   ```
   
   **Active:**
   ```
   â˜‘ Active (checkbox checked)
   ```

4. **Click:** "Add webhook"

5. **Verify:** GitHub will send a test ping event
   - Check "Recent Deliveries" tab
   - Should see âœ… green checkmark for successful delivery
   - Response should be `200 OK`

#### 2.4 Webhook Payload Example

When a PR is opened, GitHub sends this payload:

```json
{
  "action": "opened",
  "number": 123,
  "pull_request": {
    "id": 1234567890,
    "number": 123,
    "state": "open",
    "title": "Add new feature",
    "user": {
      "login": "rahulgupta2018"
    },
    "body": "This PR adds a new feature...",
    "head": {
      "sha": "abc123def456",
      "ref": "feature-branch",
      "repo": {
        "full_name": "rahulgupta2018/repo-name"
      }
    },
    "base": {
      "ref": "main"
    }
  },
  "repository": {
    "name": "repo-name",
    "full_name": "rahulgupta2018/repo-name",
    "owner": {
      "login": "rahulgupta2018"
    }
  }
}
```

Your API service will validate HMAC signature and extract:
- `repo`: `rahulgupta2018/repo-name`
- `pr_number`: `123`
- `head_sha`: `abc123def456`
- `action`: `opened`

---

### Step 3: Validate HMAC Signature in API Service

**Purpose:** Ensure webhook requests actually come from GitHub (security)

```python
# api_server.py - Webhook receiver

import hmac
import hashlib
from fastapi import FastAPI, Request, HTTPException

app = FastAPI()
WEBHOOK_SECRET = os.getenv("GITHUB_WEBHOOK_SECRET")

@app.post("/webhook/github")
async def github_webhook(request: Request):
    """
    Receive and validate GitHub webhook events.
    
    Security: Validates HMAC signature to ensure request is from GitHub.
    """
    
    # 1. Get signature from header
    signature_header = request.headers.get("X-Hub-Signature-256")
    if not signature_header:
        raise HTTPException(status_code=401, detail="Missing signature")
    
    # 2. Read raw body
    body = await request.body()
    
    # 3. Calculate expected signature
    expected_signature = "sha256=" + hmac.new(
        WEBHOOK_SECRET.encode(),
        body,
        hashlib.sha256
    ).hexdigest()
    
    # 4. Compare signatures (constant-time comparison)
    if not hmac.compare_digest(signature_header, expected_signature):
        raise HTTPException(status_code=401, detail="Invalid signature")
    
    # 5. Parse payload
    payload = await request.json()
    
    # 6. Filter: Only process "opened" and "synchronize" events
    action = payload.get("action")
    if action not in ["opened", "synchronize", "reopened"]:
        return {"status": "ignored", "reason": f"Action '{action}' not processed"}
    
    # 7. Extract PR data
    pr = payload["pull_request"]
    pr_data = {
        "repo": payload["repository"]["full_name"],
        "pr_number": pr["number"],
        "head_sha": pr["head"]["sha"],
        "action": action,
        "title": pr["title"],
        "author": pr["user"]["login"]
    }
    
    # 8. Publish to Pub/Sub queue
    from google.cloud import pubsub_v1
    
    publisher = pubsub_v1.PublisherClient()
    topic_path = f"projects/{PROJECT_ID}/topics/code-review-queue"
    
    message_data = json.dumps(pr_data).encode()
    future = publisher.publish(topic_path, message_data)
    message_id = future.result()
    
    logger.info(f"âœ… Published PR #{pr_data['pr_number']} to queue: {message_id}")
    
    # 9. Return fast ACK to GitHub (< 100ms)
    return {
        "status": "accepted",
        "message_id": message_id,
        "pr_number": pr_data["pr_number"]
    }
```

**Testing Webhook Locally:**

```bash
# Use ngrok to expose local server
ngrok http 8000

# Use ngrok URL in GitHub webhook configuration
# https://abc123.ngrok.io/webhook/github

# Start your API server
uvicorn api_server:app --host 0.0.0.0 --port 8000

# Open a PR in your repo and watch the logs!
```

---

### Step 4: Test GitHub Integration End-to-End

#### 4.1 Create Test Repository

```bash
# Create a test repository
gh repo create test-code-review --public --clone

cd test-code-review

# Add some code to review
cat > bad_code.py << 'EOF'
import os

def login(username, password):
    # SQL Injection vulnerability!
    query = f"SELECT * FROM users WHERE username='{username}' AND password='{password}'"
    db.execute(query)
    
    # Hardcoded credentials
    if username == "admin" and password == "admin123":
        return True
    
    return False
EOF

git add bad_code.py
git commit -m "Add login function"
git push origin main
```

#### 4.2 Create Pull Request

```bash
# Create feature branch
git checkout -b fix-security
echo "# Fixed security issues" >> README.md
git add README.md
git commit -m "Fix security vulnerabilities"
git push origin fix-security

# Create PR via GitHub CLI
gh pr create \
  --title "Fix security vulnerabilities in login function" \
  --body "This PR fixes SQL injection and hardcoded credentials" \
  --base main \
  --head fix-security
```

#### 4.3 Monitor Webhook Delivery

1. **GitHub UI:**
   - Go to: Repository â†’ Settings â†’ Webhooks
   - Click on your webhook
   - Click "Recent Deliveries" tab
   - Should see delivery with âœ… green checkmark
   - Click to see request/response details

2. **Cloud Logs:**
   ```bash
   # API Service logs (webhook receiver)
   gcloud logging read "resource.type=cloud_run_revision \
     AND resource.labels.service_name=code-review-api" \
     --limit 50 --format json
   
   # Worker Service logs (ADK orchestrator)
   gcloud logging read "resource.type=cloud_run_revision \
     AND resource.labels.service_name=code-review-worker" \
     --limit 50 --format json
   ```

3. **Pub/Sub Monitoring:**
   ```bash
   # Check queue depth
   gcloud pubsub topics describe code-review-queue
   
   # List subscriptions
   gcloud pubsub subscriptions list
   
   # Check dead letter queue
   gcloud pubsub topics describe code-review-dlq
   ```

#### 4.4 Verify Review Posted

1. **Check PR on GitHub:**
   - Go to your PR: https://github.com/rahulgupta2018/test-code-review/pulls
   - Should see bot comment with code review
   - Review should highlight security issues

2. **Expected Review Comment:**
   ```markdown
   # Code Review Report
   
   **Analysis ID:** abc-123-def-456
   **Date:** 2025-11-29 10:30:00 UTC
   **Source:** github_webhook
   
   ## ğŸ§  Analysis Strategy
   
   **Agents Selected:** security, code_quality
   **Execution Mode:** parallel
   **Reasoning:** Detected security-related code changes
   
   ## ğŸ“Š Executive Summary
   
   ğŸ”´ **2 Critical Issues Found**
   
   ## ğŸ” Detailed Findings
   
   ### ğŸ”’ Security Analysis
   
   **CRITICAL: SQL Injection Vulnerability (Line 5)**
   - User input directly concatenated into SQL query
   - Recommendation: Use parameterized queries
   
   **CRITICAL: Hardcoded Credentials (Line 9)**
   - Admin password hardcoded in source code
   - Recommendation: Use environment variables
   
   ## ğŸ’¡ Recommendations
   
   1. Replace string concatenation with parameterized queries
   2. Move credentials to environment variables
   3. Add input validation for username/password
   
   ---
   *Powered by ADK Multi-Agent Code Review System*
   ```

---

### Step 5: Repository-Specific Configuration

#### 5.1 Configure Branch Protection Rules

**Purpose:** Require code review approval before merging

1. **Go to:** Repository â†’ Settings â†’ Branches
2. **Add rule for:** `main` branch
3. **Settings:**
   ```
   â˜‘ Require a pull request before merging
   â˜‘ Require approvals: 1
   â˜ Require review from Code Owners (optional)
   â˜‘ Require status checks to pass before merging
       - Add: code-review-bot
   â˜‘ Require conversation resolution before merging
   â˜ Require linear history (optional)
   ```

#### 5.2 Add CODEOWNERS File (Optional)

Create `.github/CODEOWNERS` in your repository:

```bash
# .github/CODEOWNERS

# Global owners
* @rahulgupta2018

# Specific paths
/src/security/ @rahulgupta2018 @security-team
/src/api/ @rahulgupta2018 @backend-team
*.py @rahulgupta2018

# Documentation
/docs/ @rahulgupta2018
*.md @rahulgupta2018
```

#### 5.3 Configure Notifications

**Purpose:** Get notified when code reviews are posted

1. **GitHub Notifications:**
   - Go to: https://github.com/settings/notifications
   - Enable: "Pull request reviews"
   - Choose: Email or Web notification

2. **Email Notifications:**
   ```bash
   # Configure in repository settings
   # Settings â†’ Notifications â†’ Email notifications
   ```

3. **Slack Integration (Optional):**
   ```bash
   # Add GitHub app to Slack workspace
   /github subscribe rahulgupta2018/repo-name reviews
   ```

---

## ğŸ§ª Testing Checklist

### Before Going to Production

- [ ] **Personal Access Token created** with correct scopes
- [ ] **Webhook configured** with valid secret
- [ ] **HMAC validation working** (test with invalid secret)
- [ ] **Pub/Sub queue created** and configured
- [ ] **Dead letter queue created** for failed messages
- [ ] **Cloud Run services deployed** (API + Worker)
- [ ] **Secrets stored** in Google Secret Manager
- [ ] **Test PR created** and reviewed successfully
- [ ] **Review posted** to GitHub with correct formatting
- [ ] **Concurrent PRs tested** (open 3-5 PRs simultaneously)
- [ ] **Error handling tested** (invalid repo, rate limits)
- [ ] **Monitoring setup** (Cloud Logging, alerting)
- [ ] **Cost monitoring** enabled (GCP billing alerts)

### Test Scenarios

```bash
# Scenario 1: Valid PR (should post review)
gh pr create --title "Test PR" --body "Test"

# Scenario 2: Invalid webhook signature (should reject)
curl -X POST https://your-api.com/webhook/github \
  -H "X-Hub-Signature-256: sha256=invalid" \
  -d '{"action":"opened"}'

# Scenario 3: Concurrent PRs (should handle all)
for i in {1..5}; do
  gh pr create --title "Concurrent PR $i" --body "Test" &
done
wait

# Scenario 4: Large PR with 50+ files (should handle)
# Create PR with many file changes and verify processing

# Scenario 5: Trigger rate limit (should retry)
# Open many PRs quickly and verify retries work
```

---

## â“ Cloud Pub/Sub: Do We Need It?

### When to Use Cloud Pub/Sub

âœ… **YES** - Use Pub/Sub when:

1. **Multiple Concurrent PRs**: GitHub sends multiple webhooks simultaneously
2. **Rate Limiting**: Need to throttle requests to Gemini API (15 RPM free tier)
3. **Retry Logic**: Webhook processing might fail (API errors, timeouts)
4. **Decoupling**: Separate webhook receiver (fast ACK) from processing (slow)
5. **Scaling**: Worker service auto-scales based on queue depth

### When to Skip Pub/Sub

âŒ **NO** - Skip Pub/Sub when:

1. **Low Volume**: < 10 PRs/day, synchronous processing acceptable
2. **Development/Testing**: Local testing with direct API calls
3. **Single Tenant**: One repository, predictable load
4. **Cost Sensitivity**: Pub/Sub adds cost ($0.40/million messages)

### Recommended Approach

**Phase 1 (MVP):** Skip Pub/Sub
- Direct API call from webhook â†’ worker
- Synchronous processing acceptable for testing
- Simpler deployment and debugging

**Phase 2 (Production):** Add Pub/Sub
- Handle concurrent PRs reliably
- Implement rate limiting and retry logic
- Better observability and monitoring

---

## ğŸ“Š Performance Expectations

| Metric | Phase 1 (Hardcoded) | Phase 2 (Revised) | Change |
|--------|---------------------|-------------------|--------|
| Source Detection | N/A | 300ms | +300ms |
| GitHub Data Fetch | N/A | 800ms | +800ms |
| Classification | 450ms | 450ms | Â±0 |
| Planning (Plan-ReAct) | 10ms (hardcoded) | 700ms | +690ms |
| Agent Execution | 3200ms | 3200ms | Â±0 |
| Report Synthesis | 500ms | 500ms | Â±0 |
| GitHub Publish | N/A | 400ms | +400ms |
| **Total (GitHub)** | **~3.7s** | **~6.3s** | **+2.6s** |
| **Total (Web UI)** | **~3.7s** | **~4.8s** | **+1.1s** |

**Analysis:**
- GitHub path is slower due to API calls (fetch PR + post review)
- Planning adds ~700ms but provides intelligence and explainability
- Trade-off: Slower execution for better accuracy and transparency
- Acceptable for async GitHub workflow (user expects delay anyway)

---

## âœ… Summary

### Complete Workflow (8 Steps)

**GitHub PR Path:**
```
PR Opened â†’ Webhook â†’ API Service â†’ Pub/Sub Queue â†’ Worker Service
  â†“
Step 1: SourceDetector â†’ Identifies github_webhook source
  â†“
Step 2: GitHubAgent â†’ Fetches PR files via OpenAPI
  â†“
Step 3: PlanningAgent â†’ Uses Plan-ReAct to select sub-agents
  â†“
Step 4: ExecutionPipeline â†’ Runs selected agents (parallel/sequential)
  â†“
Step 5: ReportSynthesizer â†’ Consolidates results
  â†“
Step 6: GitHubPublisher â†’ Posts review to PR via OpenAPI
  â†“
Step 7: MessageAcknowledger â†’ ACKs Pub/Sub message (cleanup)
```

**Web UI Path:**
```
User Query â†’ API Service â†’ Worker Service (optional Pub/Sub)
  â†“
Step 1: SourceDetector â†’ Identifies web_ui source
  â†“
Step 2: ClassifierAgent â†’ Determines intent (security/quality/comprehensive)
  â†“
Step 3: PlanningAgent â†’ Uses Plan-ReAct to select sub-agents
  â†“
Step 4: ExecutionPipeline â†’ Runs selected agents (parallel/sequential)
  â†“
Step 5: ReportSynthesizer â†’ Consolidates results
  â†“
Step 6: Return JSON/markdown report to user
```

### What Changed from Original Phase 2

âŒ **Removed:**
- Custom if/elif orchestration logic
- Phase 1 hardcoded agent selection
- Manual checkpointing

âœ… **Added:**
- SequentialAgent for deterministic workflow
- Decision Framework for source routing
- Plan-ReAct for intelligent agent selection
- GitHub integration pipeline
- OpenAPI tools for GitHub API
- Pub/Sub message acknowledgment for cleanup

### ADK Patterns Used

1. âœ… **SequentialAgent**: Ordered pipeline execution
2. âœ… **ParallelAgent**: Concurrent independent analyses
3. âœ… **Decision Framework**: Source-based routing
4. âœ… **PlanReActPlanner**: Intelligent agent selection
5. âœ… **OpenAPIToolset**: GitHub API integration

### Why Pub/Sub with Acknowledgment is Critical

For production GitHub integration, Pub/Sub is **essential** (not optional):

| Problem | Without Pub/Sub | With Pub/Sub + ACK |
|---------|----------------|-------------------|
| **Concurrent PRs** | Sequential processing, long queue | Parallel workers, auto-scaling |
| **GitHub Rate Limits** | Webhook timeout, review lost | Message retried automatically |
| **ADK Crashes** | Review lost, no retry | Message retried up to 3 times |
| **Webhook Timeouts** | GitHub retries webhook â†’ duplicate reviews | ACK prevents duplicates |
| **Failed Reviews** | Silent failure, user never notified | Dead letter queue, alerting |
| **Cost** | Wasted LLM tokens on duplicates | Pay only for unique reviews |

**Step 7 (MessageAcknowledger) prevents:**
- âŒ Duplicate reviews (same PR reviewed 2-3 times)
- âŒ Lost reviews (crashes with no retry)
- âŒ Silent failures (no visibility into errors)
- âŒ Rate limit cascades (GitHub blocks webhook)

### Key Benefits

- **Deterministic**: Predictable, ordered execution via SequentialAgent
- **Flexible**: Add new agents without code changes (via planner)
- **Explainable**: [PLANNING] â†’ [REASONING] â†’ [ACTION] visible to users
- **Scalable**: Pub/Sub + Cloud Run handles 50+ concurrent PRs
- **Reliable**: ACK/NACK with retries + dead letter queue
- **Cost-efficient**: No duplicate processing, pay per unique review
- **Maintainable**: Pure ADK patterns, no custom orchestration logic

---

## ğŸš€ Implementation Recommendation

### Current vs Proposed Architecture

**Current State (main.py):**
- âœ… Interactive CLI tool for local development
- âœ… Direct orchestrator invocation with Runner
- âœ… Session persistence to disk (JSON files)
- âœ… Artifact storage to disk (./artifacts)
- âš ï¸ **Can be extended for Web UI** (synchronous response model)

**Proposed Architecture:**

| Component | Purpose | File | Use Case |
|-----------|---------|------|----------|
| **main.py** | Web UI backend (synchronous) | `/main.py` | âœ… Existing - User submits code, waits for result |
| **api_server.py** | GitHub webhook receiver | `/api_server.py` | âŒ To Create - Fast webhook ACK (< 100ms) |
| **worker.py** | GitHub async processor | `/worker.py` | âŒ To Create - Heavy ADK processing (30-60s) |

**Architecture by Request Source:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WEB UI PATH (main.py)                                      â”‚
â”‚                                                             â”‚
â”‚  User Browser â†’ FastAPI /analyze endpoint                   â”‚
â”‚      â†“                                                      â”‚
â”‚  main.py: runner.run_async(user_input)                     â”‚
â”‚      â†“                                                      â”‚
â”‚  Orchestrator (Steps 1-5)                                   â”‚
â”‚      â†“                                                      â”‚
â”‚  Return JSON/markdown report immediately                    â”‚
â”‚      â†“                                                      â”‚
â”‚  User sees result in browser                                â”‚
â”‚                                                             â”‚
â”‚  Characteristics:                                           â”‚
â”‚  â€¢ Synchronous: User waits 30-60s for result               â”‚
â”‚  â€¢ Direct response: No queue, no Pub/Sub                   â”‚
â”‚  â€¢ Interactive: User can ask follow-up questions            â”‚
â”‚  â€¢ Session-based: Maintains conversation history           â”‚
â”‚  â€¢ SourceDetector output: "web_ui"                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GITHUB API PATH (api_server.py + worker.py)               â”‚
â”‚                                                             â”‚
â”‚  GitHub Webhook â†’ api_server.py /webhook/github            â”‚
â”‚      â†“                                                      â”‚
â”‚  Validate HMAC signature                                    â”‚
â”‚      â†“                                                      â”‚
â”‚  Publish to Pub/Sub queue                                   â”‚
â”‚      â†“                                                      â”‚
â”‚  Return 200 OK (< 100ms) âœ… GitHub happy                   â”‚
â”‚                                                             â”‚
â”‚  [Meanwhile, async in background...]                        â”‚
â”‚                                                             â”‚
â”‚  Pub/Sub â†’ worker.py /process                               â”‚
â”‚      â†“                                                      â”‚
â”‚  Parse PR data from message                                 â”‚
â”‚      â†“                                                      â”‚
â”‚  Orchestrator (Steps 1-6)                                   â”‚
â”‚      â†“                                                      â”‚
â”‚  Post review to GitHub PR                                   â”‚
â”‚      â†“                                                      â”‚
â”‚  ACK Pub/Sub message (Step 7) âœ… Queue cleaned             â”‚
â”‚                                                             â”‚
â”‚  Characteristics:                                           â”‚
â”‚  â€¢ Asynchronous: GitHub doesn't wait                       â”‚
â”‚  â€¢ Queue-based: Handles 50+ concurrent PRs                 â”‚
â”‚  â€¢ Fire-and-forget: Review posted later                    â”‚
â”‚  â€¢ Stateless: One-shot per PR (no session)                 â”‚
â”‚  â€¢ SourceDetector output: "github_webhook"                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Differences:**

| Aspect | main.py (Web UI) | api_server.py + worker.py (GitHub API) |
|--------|------------------|----------------------------------------|
| **Request Source** | Web UI (user browser) | GitHub webhook (API call) |
| **Response Model** | Synchronous (user waits) | Asynchronous (via Pub/Sub) |
| **User Waits?** | Yes (30-60s) | No (< 100ms ACK) |
| **Result Delivery** | HTTP response body | GitHub PR comment |
| **Session State** | Persistent (multi-turn) | Stateless (one-shot) |
| **Pub/Sub Queue** | Not needed | Required for scaling |
| **Concurrency** | 1-10 concurrent users | 50+ concurrent PRs |
| **SourceDetector** | Outputs "web_ui" | Outputs "github_webhook" |
| **Orchestrator Steps** | Steps 1-5 (no GitHub publish) | Steps 1-7 (full workflow) |

### Implementation Phases

**Phase 2A: Web UI Integration (main.py)**
1. âœ… Implement Steps 1-5 (SourceDetector â†’ ReportSynthesizer)
2. âœ… Current `main.py` already has Runner + Session + Artifacts
3. Add FastAPI endpoints to `main.py`:
   ```python
   @app.post("/analyze")
   async def analyze_code(code: str, focus: str):
       result = await runner.run_async(...)
       return {"report": result}
   ```
4. Test with Web UI (user submits code, gets report)
5. **Decision Point:** If only building Web UI, stop here! No need for `worker.py`

**Phase 2B: GitHub API Integration (api_server.py + worker.py)**
1. Create `api_server.py` (FastAPI webhook receiver)
   - Endpoint: `/webhook/github`
   - Validates HMAC signature
   - Publishes to Pub/Sub
   - Returns 200 OK (< 100ms)
2. Create `worker.py` (ADK orchestrator with Pub/Sub)
   - Endpoint: `/process`
   - Receives Pub/Sub messages
   - Runs full orchestrator (Steps 1-7)
   - Posts review to GitHub
   - ACKs message
3. Add Steps 6-7 (GitHubPublisher â†’ MessageAcknowledger)
4. Deploy both services to Cloud Run
5. Configure Pub/Sub with ACK/NACK logic
6. Set up dead letter queue
7. Configure GitHub webhook
8. **Use case:** Automated PR reviews at scale (50+ concurrent PRs)

**Architecture Status:** âœ… Design Complete - Ready for Implementation

**Key Achievement:** Replaced custom orchestration with pure ADK patterns while adding complete Pub/Sub lifecycle management (including message acknowledgment and cleanup). All 8 workflow steps are deterministic, scalable, and production-ready.

---

### ğŸ¯ Clear Recommendation

**You are correct!** The architecture is:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  main.py = Web UI Backend (Synchronous)                     â”‚
â”‚  â€¢ User submits code via browser                            â”‚
â”‚  â€¢ Waits 30-60s for analysis result                         â”‚
â”‚  â€¢ Gets markdown report back immediately                    â”‚
â”‚  â€¢ Can ask follow-up questions (session-based)              â”‚
â”‚  â€¢ SourceDetector: "web_ui" â†’ ClassifierAgent path          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  api_server.py + worker.py = GitHub API Integration (Async) â”‚
â”‚  â€¢ GitHub sends webhook on PR open                          â”‚
â”‚  â€¢ api_server.py: Validates + queues (< 100ms ACK)         â”‚
â”‚  â€¢ worker.py: Processes PR + posts review (30-60s later)    â”‚
â”‚  â€¢ No user waiting, review appears on GitHub automatically  â”‚
â”‚  â€¢ SourceDetector: "github_webhook" â†’ GitHubAgent path      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Start with Phase 2A:** Extend `main.py` for Web UI (add FastAPI endpoints)  
**Add Phase 2B later:** Create `api_server.py` + `worker.py` for GitHub automation

**You don't need both unless you want both Web UI AND GitHub integration!**

---

## ğŸ“ Complete Orchestration Flow Summary

### The Correct Mental Model

Based on ADK training documentation (https://raphaelmansuy.github.io/adk_training/docs/workflows-orchestration), here's the complete understanding:

#### 1. Workflow Agents = Containers (They DON'T do work)

```python
# These are CONTAINERS that control execution order/parallelism
SequentialAgent(sub_agents=[agent1, agent2, agent3])  # One after another
ParallelAgent(sub_agents=[agent1, agent2, agent3])    # All at once
LoopAgent(sub_agents=[critic, refiner])               # Repeat until good
```

**Key Point:** SequentialAgent, ParallelAgent, LoopAgent are **just containers**. They don't call LLMs, they don't use tools, they don't process data. They just control WHEN their sub-agents run.

#### 2. Sub-Agents = Workers (They DO the actual work)

```python
# These are regular Agents - they do actual work
SourceDetector = Agent(name="SourceDetector", model="gemini-2.5-flash", ...)
GitHubAgent = Agent(name="GitHubAgent", model="gemini-2.5-flash", tools=[...])
PlanningAgent = Agent(name="PlanningAgent", planner=PlanReActPlanner(), ...)
SecurityAgent = Agent(name="SecurityAgent", model="gemini-2.5-flash", ...)
```

**Key Point:** ALL of these are sub-agents (regular `Agent` instances). They are placed INSIDE workflow containers (SequentialAgent, ParallelAgent).

#### 3. Our Complete Architecture

```
RootOrchestrator (SequentialAgent) â† CONTAINER
â”‚
â”œâ”€ sub_agents: [SourceDetector] â† SUB-AGENT (Agent)
â”‚   â””â”€ Always runs first
â”‚   â””â”€ Outputs: {source: "github_webhook" or "web_ui"}
â”‚
â”œâ”€ routing_function: route_by_source
â”‚   â””â”€ Reads SourceDetector output
â”‚   â””â”€ Returns: "github_pipeline" or "web_pipeline"
â”‚
â””â”€ dynamic_agents: {
     
     "github_pipeline": GitHubPipeline (SequentialAgent) â† CONTAINER
                         â”‚
                         â”œâ”€ sub_agents[0]: GitHubAgent â† SUB-AGENT
                         â”‚   â””â”€ Fetches PR files from GitHub API
                         â”‚   â””â”€ Outputs: {github_pr_data}
                         â”‚
                         â”œâ”€ sub_agents[1]: PlanningAgent â† SUB-AGENT
                         â”‚   â””â”€ Uses PlanReActPlanner
                         â”‚   â””â”€ Selects which analysis agents to run
                         â”‚   â””â”€ Outputs: {execution_plan}
                         â”‚
                         â”œâ”€ (Dynamic) ExecutionPipeline â† CONTAINER
                         â”‚   â”‚  Created at runtime based on execution_plan
                         â”‚   â”‚
                         â”‚   â”œâ”€ IF plan.execution_mode == "parallel":
                         â”‚   â”‚    ParallelAgent â† CONTAINER
                         â”‚   â”‚    â”‚
                         â”‚   â”‚    â”œâ”€ SecurityAgent â† SUB-AGENT
                         â”‚   â”‚    â”œâ”€ CodeQualityAgent â† SUB-AGENT
                         â”‚   â”‚    â”œâ”€ EngineeringAgent â† SUB-AGENT
                         â”‚   â”‚    â””â”€ CarbonAgent â† SUB-AGENT
                         â”‚   â”‚
                         â”‚   â””â”€ ELSE plan.execution_mode == "sequential":
                         â”‚        SequentialAgent â† CONTAINER
                         â”‚        â”‚
                         â”‚        â”œâ”€ SecurityAgent â† SUB-AGENT
                         â”‚        â”œâ”€ CodeQualityAgent â† SUB-AGENT
                         â”‚        â”œâ”€ EngineeringAgent â† SUB-AGENT
                         â”‚        â””â”€ CarbonAgent â† SUB-AGENT
                         â”‚
                         â”œâ”€ sub_agents[2]: ReportSynthesizer â† SUB-AGENT
                         â”‚   â””â”€ Consolidates all analysis results
                         â”‚   â””â”€ Outputs: {final_report}
                         â”‚
                         â””â”€ sub_agents[3]: GitHubPublisher â† SUB-AGENT
                             â””â”€ Posts review to GitHub PR
                             â””â”€ Outputs: {github_review_url}
     
     "web_pipeline": WebPipeline (SequentialAgent) â† CONTAINER
                      â”‚
                      â”œâ”€ sub_agents[0]: ClassifierAgent â† SUB-AGENT
                      â”‚   â””â”€ Classifies user intent
                      â”‚   â””â”€ Outputs: {classification}
                      â”‚
                      â”œâ”€ sub_agents[1]: PlanningAgent â† SUB-AGENT
                      â”‚   â””â”€ (same as GitHub pipeline)
                      â”‚
                      â”œâ”€ (Dynamic) ExecutionPipeline â† CONTAINER
                      â”‚   â””â”€ (same as GitHub pipeline)
                      â”‚
                      â””â”€ sub_agents[2]: ReportSynthesizer â† SUB-AGENT
                          â””â”€ (same as GitHub pipeline)
   }
```

#### 4. What Makes Each Component What It Is

| Component | Type | Why? | Evidence |
|-----------|------|------|----------|
| `RootOrchestrator` | SequentialAgent (Container) | Has `sub_agents=[]` and `dynamic_agents={}` | ADK pattern |
| `GitHubPipeline` | SequentialAgent (Container) | Has `sub_agents=[github_agent, planning_agent, ...]` | ADK pattern |
| `WebPipeline` | SequentialAgent (Container) | Has `sub_agents=[classifier, planning_agent, ...]` | ADK pattern |
| `ExecutionPipeline` | ParallelAgent OR SequentialAgent (Container) | Has `sub_agents=[security, quality, ...]` | ADK pattern |
| `SourceDetector` | Agent (Sub-agent) | Created with `Agent(name=..., model=..., instruction=...)` | Does work |
| `GitHubAgent` | Agent (Sub-agent) | Created with `Agent(name=..., tools=[...])` | Does work |
| `ClassifierAgent` | Agent (Sub-agent) | Created with `Agent(name=..., model=...)` | Does work |
| `PlanningAgent` | Agent (Sub-agent) | Created with `Agent(name=..., planner=...)` | Does work |
| `SecurityAgent` | Agent (Sub-agent) | Created with `Agent(name=..., tools=[...])` | Does work |
| `CodeQualityAgent` | Agent (Sub-agent) | Created with `Agent(name=..., tools=[...])` | Does work |
| `EngineeringAgent` | Agent (Sub-agent) | Created with `Agent(name=..., tools=[...])` | Does work |
| `CarbonAgent` | Agent (Sub-agent) | Created with `Agent(name=..., tools=[...])` | Does work |
| `ReportSynthesizer` | Agent (Sub-agent) | Created with `Agent(name=..., model=...)` | Does work |
| `GitHubPublisher` | Agent (Sub-agent) | Created with `Agent(name=..., tools=[...])` | Does work |

**CRITICAL:** Every single one of SourceDetector, GitHubAgent, ClassifierAgent, PlanningAgent, SecurityAgent, CodeQualityAgent, EngineeringAgent, CarbonAgent, ReportSynthesizer, GitHubPublisher is a **sub-agent** (regular Agent instance). None of them are workflow orchestrators!

#### 5. How Data Flows Between Sub-Agents

```python
# Agent 1 writes to state
SourceDetector:
  output_key="source_detection"
  â†’ Saves output to: state["source_detection"]

# Agent 2 reads from state via instruction interpolation
GitHubAgent:
  instruction="GitHub Context: {source_detection.github_context}"
  â†’ Reads: state["source_detection"]["github_context"]
  â†’ LLM sees the actual data in the prompt
  output_key="github_pr_data"
  â†’ Saves output to: state["github_pr_data"]

# Agent 3 reads from multiple previous agents
ReportSynthesizer:
  instruction="Results: {security_results}, {code_quality_results}"
  â†’ Reads: state["security_results"], state["code_quality_results"]
  â†’ LLM consolidates all data
  output_key="final_report"
  â†’ Saves output to: state["final_report"]
```

**Key Mechanism:** `output_key` + instruction interpolation `{key_name}`

#### 6. How Dynamic Routing Works

```python
# Step 1: SourceDetector runs and outputs
state["source_detection"] = {
  "source": "github_webhook",  # or "web_ui"
  "github_context": {...}
}

# Step 2: Routing function is called
def route_by_source(context, result):
    source = result.get('source')  # "github_webhook"
    if source == 'github_webhook':
        return 'github_pipeline'  # â† Key name in dynamic_agents
    else:
        return 'web_pipeline'

# Step 3: RootOrchestrator selects the pipeline
# It runs: dynamic_agents['github_pipeline']
# Which is: SequentialAgent([github_agent, planning_agent, ...])
```

#### 7. How Dynamic Execution Works

```python
# Step 1: PlanningAgent outputs execution plan
state["execution_plan"] = {
  "selected_agents": ["security", "code_quality"],
  "execution_mode": "parallel"
}

# Step 2: We intercept after PlanningAgent completes
if event.author == "PlanningAgent" and event.turn_complete:
    plan = event.context.session.state["execution_plan"]
    
    # Step 3: Create appropriate workflow container
    if plan["execution_mode"] == "parallel":
        execution_pipeline = ParallelAgent(
            sub_agents=[security_agent, code_quality_agent]
        )
    else:
        execution_pipeline = SequentialAgent(
            sub_agents=[security_agent, code_quality_agent]
        )
    
    # Step 4: Run the dynamically created pipeline
    async for exec_event in execution_pipeline.run_async(context):
        yield exec_event
```

**Key Point:** ExecutionPipeline is created AT RUNTIME based on what PlanningAgent decides!

#### 8. Complete Execution Trace

```
User request arrives
â†“
Runner.run_async(user_message, request_metadata)
â†“
RootOrchestrator (SequentialAgent) starts
  â†“
  â”œâ”€ SourceDetector runs
  â”‚   Input: {user_message, request_metadata}
  â”‚   Output: {source: "github_webhook", github_context: {...}}
  â”‚   Saves to: state["source_detection"]
  â†“
  â”œâ”€ routing_function(context, state["source_detection"])
  â”‚   Returns: "github_pipeline"
  â†“
  â””â”€ GitHubPipeline (SequentialAgent) starts
      â†“
      â”œâ”€ GitHubAgent runs
      â”‚   Input: {source_detection.github_context}
      â”‚   Calls: fetch_pr_files(repo, pr_number)
      â”‚   Output: {github_pr_data: {...}}
      â”‚   Saves to: state["github_pr_data"]
      â†“
      â”œâ”€ PlanningAgent runs
      â”‚   Input: {github_pr_data}
      â”‚   LLM analyzes code changes
      â”‚   Calls: select_security_analysis(), select_quality_analysis()
      â”‚   Output: {execution_plan: {selected_agents: [...], execution_mode: "parallel"}}
      â”‚   Saves to: state["execution_plan"]
      â†“
      â”œâ”€ (Event intercepted by our code)
      â”‚   We read: state["execution_plan"]
      â”‚   We create: ParallelAgent([security_agent, code_quality_agent])
      â”‚   We run it:
      â”‚     â†“
      â”‚     â”œâ”€ SecurityAgent runs (in parallel)
      â”‚     â”‚   Output: {security_results: [...]}
      â”‚     â”œâ”€ CodeQualityAgent runs (in parallel)
      â”‚     â”‚   Output: {code_quality_results: [...]}
      â”‚     â””â”€ Both complete, results merged into state
      â†“
      â”œâ”€ ReportSynthesizer runs
      â”‚   Input: {security_results, code_quality_results}
      â”‚   LLM consolidates findings
      â”‚   Output: {final_report: "# Code Review Report\n..."}
      â”‚   Saves to: state["final_report"]
      â†“
      â””â”€ GitHubPublisher runs
          Input: {final_report, source_detection.github_context}
          Calls: post_review_comment(repo, pr_number, final_report)
          Output: {github_review_url: "https://..."}
          Saves to: state["github_review_url"]

Workflow complete - all events yielded back to caller
```

#### 9. Final Clarity Check

**Q: Is SourceDetector a sub-agent or orchestrator?**  
A: **Sub-agent**. It's a regular `Agent(...)` that does work (calls LLM to analyze request metadata).

**Q: Is GitHubAgent a sub-agent or orchestrator?**  
A: **Sub-agent**. It's a regular `Agent(...)` with tools that fetches PR data.

**Q: Is ClassifierAgent a sub-agent or orchestrator?**  
A: **Sub-agent**. It's a regular `Agent(...)` that classifies user intent.

**Q: Is PlanningAgent a sub-agent or orchestrator?**  
A: **Sub-agent**. It's a regular `Agent(...)` with a planner that selects which agents to run.

**Q: Is GitHubPipeline a sub-agent or orchestrator?**  
A: **Neither**. It's a **workflow container** (SequentialAgent) that contains sub-agents.

**Q: Is ExecutionPipeline a sub-agent or orchestrator?**  
A: **Neither**. It's a **workflow container** (ParallelAgent or SequentialAgent) created dynamically.

**Q: What makes something a workflow container vs sub-agent?**  
A:
- **Workflow Container:** Created with `SequentialAgent()`, `ParallelAgent()`, or `LoopAgent()`. Has `sub_agents=[]` parameter.
- **Sub-Agent:** Created with `Agent()`. Has `model=`, `instruction=`, `tools=` parameters. Does actual work.

---

## âœ… Summary

**Orchestration Architecture:**
- **3 workflow containers:** RootOrchestrator, GitHubPipeline/WebPipeline, ExecutionPipeline
- **10 sub-agents:** SourceDetector, GitHubAgent, ClassifierAgent, PlanningAgent, SecurityAgent, CodeQualityAgent, EngineeringAgent, CarbonAgent, ReportSynthesizer, GitHubPublisher

**Key Patterns:**
- âœ… SequentialAgent for ordered execution (assembly line)
- âœ… ParallelAgent for concurrent execution (fan-out/gather)
- âœ… Dynamic routing via `routing_function` (conditional branching)
- âœ… Dynamic execution via runtime pipeline creation (intelligent agent selection)
- âœ… State passing via `output_key` + instruction interpolation

**No Custom Orchestration:**
- âŒ No if/elif logic in our code
- âŒ No custom orchestrator classes
- âŒ No manual agent invocation
- âœ… Pure ADK patterns (SequentialAgent, ParallelAgent, routing functions)

This is the correct, ADK-compliant, production-ready orchestration architecture! ğŸ‰
